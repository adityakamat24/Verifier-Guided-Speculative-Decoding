{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1ffae-c6a1-4af9-a562-9e6ea4d16dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR      : /workspace/vspec\n",
      "DATA_PATH     : /workspace/vspec/data/vspec_train.jsonl\n",
      "VERIFIER_PATH : /workspace/vspec/ckpt/vspec_verifier.pt\n",
      "ENHANCED_PATH : /workspace/vspec/ckpt/vspec_verifier_enhanced.pt\n",
      "Visible GPUs  : 2\n",
      "  cuda:0 -> NVIDIA H100 80GB HBM3\n",
      "    Memory: 85.0 GB\n",
      "    SMs: 132\n",
      "  cuda:1 -> NVIDIA H100 80GB HBM3\n",
      "    Memory: 85.0 GB\n",
      "    SMs: 132\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, torch, pathlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_DIR = os.environ.get(\"BASE_DIR\", \"/workspace/vspec\")\n",
    "pathlib.Path(BASE_DIR).mkdir(parents=True, exist_ok=True)\n",
    "for sub in (\"data\", \"ckpt\", \"hf/hub\", \"logs\", \"profiles\"):\n",
    "   pathlib.Path(f\"{BASE_DIR}/{sub}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ[\"HF_HOME\"] = f\"{BASE_DIR}/hf\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = f\"{BASE_DIR}/hf/hub\"\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "os.environ[\"DATA_PATH\"] = f\"{BASE_DIR}/data/vspec_train.jsonl\"\n",
    "os.environ[\"VERIFIER_PATH\"] = f\"{BASE_DIR}/ckpt/vspec_verifier.pt\"\n",
    "os.environ[\"ENHANCED_VERIFIER_PATH\"] = f\"{BASE_DIR}/ckpt/vspec_verifier_enhanced.pt\"\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\" \n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   torch.cuda.empty_cache()\n",
    "   torch.cuda.set_per_process_memory_fraction(0.95)  \n",
    "\n",
    "print(\"BASE_DIR      :\", BASE_DIR)\n",
    "print(\"DATA_PATH     :\", os.environ[\"DATA_PATH\"])\n",
    "print(\"VERIFIER_PATH :\", os.environ[\"VERIFIER_PATH\"])\n",
    "print(\"ENHANCED_PATH :\", os.environ[\"ENHANCED_VERIFIER_PATH\"])\n",
    "print(\"Visible GPUs  :\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "   print(f\"  cuda:{i} -> {torch.cuda.get_device_name(i)}\")\n",
    "   props = torch.cuda.get_device_properties(i)\n",
    "   print(f\"    Memory: {props.total_memory / 1e9:.1f} GB\")\n",
    "   print(f\"    SMs: {props.multi_processor_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d5c8cc-5920-48af-8680-d88f4e5d97a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
      "Collecting hf-transfer\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.8.0.dev20250319+cu128)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (108 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch>=2.0.0->accelerate) (77.0.1)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Downloading transformers-4.55.2-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m196.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m248.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m245.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m202.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m135.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m242.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fonttools-4.59.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m269.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m265.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 kB\u001b[0m \u001b[31m158.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m230.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m291.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m223.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
      "Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, tqdm, threadpoolctl, scipy, safetensors, regex, pyarrow, propcache, ninja, multidict, kiwisolver, joblib, hf-xet, hf-transfer, frozenlist, fonttools, dill, cycler, contourpy, aiohappyeyeballs, yarl, scikit-learn, pandas, multiprocess, matplotlib, huggingface-hub, aiosignal, tokenizers, seaborn, aiohttp, transformers, bitsandbytes, accelerate, datasets\n",
      "Successfully installed accelerate-1.10.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 bitsandbytes-0.47.0 contourpy-1.3.3 cycler-0.12.1 datasets-4.0.0 dill-0.3.8 fonttools-4.59.1 frozenlist-1.7.0 hf-transfer-0.1.9 hf-xet-1.1.7 huggingface-hub-0.34.4 joblib-1.5.1 kiwisolver-1.4.9 matplotlib-3.10.5 multidict-6.6.4 multiprocess-0.70.16 ninja-1.13.0 pandas-2.3.1 propcache-0.3.2 pyarrow-21.0.0 pytz-2025.2 regex-2025.7.34 safetensors-0.6.2 scikit-learn-1.7.1 scipy-1.16.1 seaborn-0.13.2 threadpoolctl-3.6.0 tokenizers-0.21.4 tqdm-4.67.1 transformers-4.55.2 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate safetensors datasets bitsandbytes hf-transfer pandas numpy matplotlib seaborn tqdm scipy scikit-learn ninja packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc9dbf8-7c85-4fed-b881-97ea884a8a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn\n",
      "  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.8.0.dev20250319+cu128)\n",
      "Collecting einops (from flash-attn)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch->flash-attn) (77.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.8.3-cp311-cp311-linux_x86_64.whl size=256043372 sha256=3d41b2fc55753faa7f45d6568ea73a96b96afb48b82994ab9b49bcbcb6c87588\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/31/1f/4b22dd7295b3cb064b8fa9038f6d58fb15c9571555b2d7c39c\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: einops, flash-attn\n",
      "Successfully installed einops-0.8.1 flash-attn-2.8.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5c45e-c7fa-4b43-a9a6-33c0934fa6eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models with enhanced features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1c093da7bf459b891d36d57cb0501d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275d5e134b3a4103a7317f0252c3f214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Target on cuda:1\n",
      "✓ Drafter on cuda:0\n",
      "Target attention: sdpa\n",
      "Drafter attention: sdpa\n",
      "Torch: 2.8.0.dev20250319+cu128 CUDA: 12.8\n",
      "✓ Enhanced configuration loaded\n",
      "  K range: [4, 14]\n",
      "  Tau range: [0.65, 0.85]\n",
      "  Stream manager initialized\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, time, json, random, math, warnings\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple, Optional, Any, Union, Dict\n",
    "from collections import defaultdict, deque\n",
    "from contextlib import contextmanager\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "TARGET_NAME   = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "DRAFTER_NAME  = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "TARGET_DEV    = \"cuda:1\"\n",
    "DRAFTER_DEV   = \"cuda:0\"\n",
    "DTYPE = \"bfloat16\"\n",
    "\n",
    "@dataclass\n",
    "class AdaptiveConfig:\n",
    "    k_init: int = 12\n",
    "    k_min: int = 4\n",
    "    k_max: int = 14\n",
    "    tau_init: float = 0.72\n",
    "    tau_min: float = 0.65\n",
    "    tau_max: float = 0.85\n",
    "    margin_init: float = 0.19\n",
    "    margin_min: float = 0.10\n",
    "    margin_max: float = 0.35\n",
    "    adaptation_rate: float = 0.02\n",
    "    weak_threshold: int = 2\n",
    "    confidence_window: int = 8\n",
    "\n",
    "CONFIG = AdaptiveConfig()\n",
    "\n",
    "class NonBlockingTimer:\n",
    "    \"\"\"Timer that doesn't block GPU execution\"\"\"\n",
    "    def __init__(self, enabled=True):\n",
    "        self.enabled = enabled\n",
    "        self.events = defaultdict(list)\n",
    "        self.cpu_times = defaultdict(list)\n",
    "        \n",
    "    @contextmanager\n",
    "    def timer(self, name):\n",
    "        if not self.enabled:\n",
    "            yield\n",
    "            return\n",
    "            \n",
    "        if torch.cuda.is_available():\n",
    "            start = torch.cuda.Event(enable_timing=True)\n",
    "            end = torch.cuda.Event(enable_timing=True)\n",
    "            start.record()\n",
    "            yield\n",
    "            end.record()\n",
    "            self.events[name].append((start, end))\n",
    "        else:\n",
    "            start = time.perf_counter()\n",
    "            yield\n",
    "            elapsed = time.perf_counter() - start\n",
    "            self.cpu_times[name].append(elapsed)\n",
    "    \n",
    "    def report(self):\n",
    "        \"\"\"Get timing results (syncs only here)\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        if self.events:\n",
    "            torch.cuda.synchronize()\n",
    "            for name, event_pairs in self.events.items():\n",
    "                times = [start.elapsed_time(end) / 1000.0 for start, end in event_pairs]\n",
    "                results[name] = {\n",
    "                    'mean_ms': np.mean(times) * 1000,\n",
    "                    'total_s': sum(times),\n",
    "                    'count': len(times),\n",
    "                    'std_ms': np.std(times) * 1000\n",
    "                }\n",
    "        \n",
    "        for name, times in self.cpu_times.items():\n",
    "            results[name] = {\n",
    "                'mean_ms': np.mean(times) * 1000,\n",
    "                'total_s': sum(times),\n",
    "                'count': len(times),\n",
    "                'std_ms': np.std(times) * 1000\n",
    "            }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def reset(self):\n",
    "        self.events.clear()\n",
    "        self.cpu_times.clear()\n",
    "\n",
    "monitor = NonBlockingTimer(enabled=True)\n",
    "\n",
    "@dataclass\n",
    "class ModelBundle:\n",
    "    name: str\n",
    "    tok: AutoTokenizer\n",
    "    model: AutoModelForCausalLM\n",
    "    dtype: torch.dtype\n",
    "    device: torch.device\n",
    "    compile_enabled: bool = False\n",
    "\n",
    "@dataclass\n",
    "class KVState:\n",
    "    past: Any\n",
    "    last_logits: torch.Tensor\n",
    "    seq_len: int = 0\n",
    "\n",
    "    def memory_usage(self):\n",
    "        \"\"\"Estimate KV cache memory usage\"\"\"\n",
    "        if self.past is None:\n",
    "            return 0\n",
    "        total_bytes = 0\n",
    "        for layer_kv in self.past:\n",
    "            for tensor in layer_kv:\n",
    "                total_bytes += tensor.element_size() * tensor.nelement()\n",
    "        return total_bytes / 1e9  # GB\n",
    "\n",
    "\n",
    "def pick_attn_impl(device: Optional[str]) -> str:\n",
    "    \"\"\"Prefer FlashAttention v2 if importable; otherwise fall back to SDPA. CPU uses eager.\"\"\"\n",
    "    if device is None or device == \"cpu\":\n",
    "        return \"eager\"\n",
    "    try:\n",
    "        import flash_attn  # noqa: F401\n",
    "        return \"flash_attention_2\"\n",
    "    except Exception:\n",
    "        return \"sdpa\"\n",
    "\n",
    "def pick_dtype(requested: str) -> str:\n",
    "    \"\"\"Use bf16 only on Ampere+ (SM80+). Otherwise, downshift to fp16.\"\"\"\n",
    "    if requested.lower() == \"bfloat16\":\n",
    "        try:\n",
    "            if torch.cuda.is_available():\n",
    "                major, _ = torch.cuda.get_device_capability()\n",
    "                if major < 8:\n",
    "                    warnings.warn(\"bfloat16 requested but GPU < SM80; using float16 instead.\")\n",
    "                    return \"float16\"\n",
    "        except Exception:\n",
    "            pass\n",
    "    return requested\n",
    "\n",
    "def load_bundle(model_name: str, dtype: str = \"bfloat16\",\n",
    "                load_in_4bit: bool = False, device: Optional[str] = None) -> ModelBundle:\n",
    "    dtype = pick_dtype(dtype)\n",
    "    torch_dtype = {\n",
    "        \"float16\": torch.float16,\n",
    "        \"bfloat16\": torch.bfloat16,\n",
    "        \"float32\": torch.float32\n",
    "    }[dtype]\n",
    "\n",
    "    cache_dir = os.environ.get(\"TRANSFORMERS_CACHE\", None)\n",
    "\n",
    "    tok = AutoTokenizer.from_pretrained(model_name, use_fast=True, cache_dir=cache_dir)\n",
    "    if tok.pad_token is None:\n",
    "        tok.pad_token = tok.eos_token\n",
    "\n",
    "    devmap = {\"\": device} if device is not None else \"auto\"\n",
    "    attn_impl = pick_attn_impl(device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    common_kwargs = dict(\n",
    "        device_map=devmap,\n",
    "        torch_dtype=torch_dtype,\n",
    "        cache_dir=cache_dir,\n",
    "        attn_implementation=attn_impl\n",
    "    )\n",
    "\n",
    "    if load_in_4bit:\n",
    "        bnb = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch_dtype,\n",
    "        )\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb, **common_kwargs)\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, **common_kwargs)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    try:\n",
    "        from torch.backends.cuda import sdp_kernel\n",
    "        sdp_kernel(enable_flash=True, enable_mem_efficient=True, enable_math=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        first_param_dev = next(model.parameters()).device\n",
    "    except StopIteration:\n",
    "        first_param_dev = torch.device(device if device else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    bundle = ModelBundle(model_name, tok, model, torch_dtype, first_param_dev)\n",
    "    return bundle\n",
    "\n",
    "print(\"Loading models with enhanced features...\")\n",
    "target  = load_bundle(TARGET_NAME,  dtype=DTYPE, device=TARGET_DEV)\n",
    "drafter = load_bundle(DRAFTER_NAME, dtype=DTYPE, device=DRAFTER_DEV)\n",
    "\n",
    "print(f\"✓ Target on {target.device}\")\n",
    "print(f\"✓ Drafter on {drafter.device}\")\n",
    "print(\"Target attention:\", getattr(target.model.config, \"_attn_implementation\", \"unknown\"))\n",
    "print(\"Drafter attention:\", getattr(drafter.model.config, \"_attn_implementation\", \"unknown\"))\n",
    "print(\"Torch:\", torch.__version__, \"CUDA:\", torch.version.cuda)\n",
    "\n",
    "\n",
    "class StreamManager:\n",
    "    \"\"\"Manage CUDA streams for parallel execution\"\"\"\n",
    "    def __init__(self, target_device, drafter_device):\n",
    "        self.target_device = torch.device(target_device)\n",
    "        self.drafter_device = torch.device(drafter_device)\n",
    "        \n",
    "        with torch.cuda.device(self.target_device):\n",
    "            self.target_stream = torch.cuda.Stream()\n",
    "        with torch.cuda.device(self.drafter_device):\n",
    "            self.drafter_stream = torch.cuda.Stream()\n",
    "            \n",
    "    def get_target_stream(self):\n",
    "        return self.target_stream\n",
    "    \n",
    "    def get_drafter_stream(self):\n",
    "        return self.drafter_stream\n",
    "\n",
    "stream_mgr = StreamManager(TARGET_DEV, DRAFTER_DEV)\n",
    "\n",
    "@torch.no_grad()\n",
    "def init_state(bundle: ModelBundle, input_ids: torch.Tensor) -> KVState:\n",
    "    with monitor.timer(\"init_state\"):\n",
    "        out = bundle.model(input_ids=input_ids, use_cache=True)\n",
    "        return KVState(\n",
    "            past=getattr(out, \"past_key_values\", None),\n",
    "            last_logits=out.logits[:, -1, :],\n",
    "            seq_len=input_ids.shape[1]\n",
    "        )\n",
    "\n",
    "@torch.no_grad()\n",
    "def greedy_step_with_cache(bundle: ModelBundle, state: KVState,\n",
    "                           next_token: Optional[Union[int, torch.Tensor]] = None) -> Tuple[torch.Tensor, KVState]:\n",
    "    dev = state.last_logits.device\n",
    "\n",
    "    if next_token is None:\n",
    "        chosen_id = int(state.last_logits.argmax(-1).item())\n",
    "    elif isinstance(next_token, torch.Tensor):\n",
    "        chosen_id = int(next_token.view(-1)[0].item())\n",
    "    else:\n",
    "        chosen_id = int(next_token)\n",
    "\n",
    "    inp = torch.tensor([[chosen_id]], device=dev, dtype=torch.long)\n",
    "\n",
    "    with monitor.timer(\"model_forward_step\"):\n",
    "        out = bundle.model(input_ids=inp, past_key_values=state.past, use_cache=True)\n",
    "\n",
    "    return inp, KVState(\n",
    "        past=getattr(out, \"past_key_values\", None),\n",
    "        last_logits=out.logits[:, -1, :],\n",
    "        seq_len=state.seq_len + 1\n",
    "    )\n",
    "\n",
    "@torch.no_grad()\n",
    "def drafter_draft_chunk_cached(drafter_bundle: ModelBundle, d_state: KVState, k: int):\n",
    "    \"\"\"Original function for compatibility\"\"\"\n",
    "    tokens, per_step_logits, state = [], [], d_state\n",
    "    for _ in range(k):\n",
    "        next_id = int(state.last_logits.argmax(-1).item())\n",
    "        per_step_logits.append(state.last_logits)\n",
    "        _, state = greedy_step_with_cache(drafter_bundle, state, next_id)\n",
    "        tokens.append(next_id)\n",
    "    return tokens, per_step_logits, state\n",
    "\n",
    "@torch.no_grad()\n",
    "def target_verify_and_update(target_bundle: ModelBundle, t_state: KVState, draft_tokens: List[int]) -> Tuple[int, KVState]:\n",
    "    \"\"\"Original function for compatibility\"\"\"\n",
    "    L, state = 0, t_state\n",
    "    for tok in draft_tokens:\n",
    "        if int(state.last_logits.argmax(-1).item()) != tok:\n",
    "            break\n",
    "        _, state = greedy_step_with_cache(target_bundle, state, tok)\n",
    "        L += 1\n",
    "    return L, state\n",
    "\n",
    "def decode_text(tok: AutoTokenizer, ids: List[int]) -> str:\n",
    "    return tok.decode(ids, skip_special_tokens=True)\n",
    "\n",
    "def safe_shared_tokenizer(drafter_tok, target_tok):\n",
    "    ok_family = (\"Qwen2.5\" in (getattr(drafter_tok, \"name_or_path\", \"\") or \"\")) and (\"Qwen2.5\" in (getattr(target_tok, \"name_or_path\", \"\") or \"\"))\n",
    "    ok_size = drafter_tok.vocab_size == target_tok.vocab_size\n",
    "    if not (ok_family and ok_size):\n",
    "        raise ValueError(\"Drafter/Target must share tokenizer. Use Qwen2.5 3B + 14B as configured.\")\n",
    "\n",
    "safe_shared_tokenizer(drafter.tok, target.tok)\n",
    "\n",
    "\n",
    "TOPK = 16\n",
    "RECENT_N = 256\n",
    "FEAT_PER_POS = 10\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "MATH_TEMPL = [\n",
    "    \"Compute {a} * {b} step by step.\",\n",
    "    \"If a car travels {a} km at {b} km/h and then {c} km at {d} km/h, what's the average speed?\",\n",
    "    \"Solve for x: {a}x + {b} = {c}. Show steps.\",\n",
    "]\n",
    "CODE_TEMPL = [\n",
    "    \"Write a Python function to check if a number is prime.\",\n",
    "    \"Implement a function to reverse a linked list in Python.\",\n",
    "    \"Given a list of integers, return a list of unique elements preserving order (Python).\",\n",
    "]\n",
    "REASON_TEMPL = [\n",
    "    \"Explain gradient descent to a 12-year-old.\",\n",
    "    \"Summarize the main causes of World War I in 3 sentences.\",\n",
    "    \"Why is the sky blue? One paragraph.\",\n",
    "]\n",
    "\n",
    "def sample_prompts(n=200):\n",
    "    ps = []\n",
    "    for _ in range(n):\n",
    "        t = random.choice([0,1,2])\n",
    "        if t==0:\n",
    "            a,b,c,d = [random.randint(10,99) for _ in range(4)]\n",
    "            ps.append(random.choice(MATH_TEMPL).format(a=a,b=b,c=c,d=d))\n",
    "        elif t==1:\n",
    "            ps.append(random.choice(CODE_TEMPL))\n",
    "        else:\n",
    "            ps.append(random.choice(REASON_TEMPL))\n",
    "    return ps\n",
    "\n",
    "print(f\"✓ Enhanced configuration loaded\")\n",
    "print(f\"  K range: [{CONFIG.k_min}, {CONFIG.k_max}]\")\n",
    "print(f\"  Tau range: [{CONFIG.tau_min}, {CONFIG.tau_max}]\")\n",
    "print(f\"  Stream manager initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc00275-ad9f-456e-a6e9-e003469fbe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Parallel speculation components loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class PipelinedSpeculator:\n",
    "    \"\"\"Pipeline drafting and verification for true parallelism\"\"\"\n",
    "    \n",
    "    def __init__(self, target_bundle, drafter_bundle, stream_mgr):\n",
    "        self.target = target_bundle\n",
    "        self.drafter = drafter_bundle\n",
    "        self.stream_mgr = stream_mgr\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def draft_async(self, d_state: KVState, k: int):\n",
    "        \"\"\"Draft on drafter stream asynchronously - NO SYNC\"\"\"\n",
    "        with torch.cuda.stream(self.stream_mgr.drafter_stream):\n",
    "            tokens = []\n",
    "            logits_list = []\n",
    "            state = d_state\n",
    "            \n",
    "            for _ in range(k):\n",
    "                next_id = int(state.last_logits.argmax(-1).item())\n",
    "                tokens.append(next_id)\n",
    "                logits_list.append(state.last_logits)\n",
    "                \n",
    "                inp = torch.tensor([[next_id]], device=state.last_logits.device, dtype=torch.long)\n",
    "                out = self.drafter.model(input_ids=inp, past_key_values=state.past, use_cache=True)\n",
    "                state = KVState(\n",
    "                    past=out.past_key_values,\n",
    "                    last_logits=out.logits[:, -1, :],\n",
    "                    seq_len=state.seq_len + 1\n",
    "                )\n",
    "            \n",
    "            return tokens, logits_list, state\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def verify_async(self, t_state: KVState, draft_tokens: List[int], L_hat: int):\n",
    "        \"\"\"Verify on target stream asynchronously - NO SYNC\"\"\"\n",
    "        with torch.cuda.stream(self.stream_mgr.target_stream):\n",
    "            if L_hat <= 0:\n",
    "                return False, 0, t_state\n",
    "            \n",
    "            dev = t_state.last_logits.device\n",
    "            toks = torch.tensor(draft_tokens[:L_hat], device=dev, dtype=torch.long)\n",
    "            inp = toks.unsqueeze(0)\n",
    "            \n",
    "            out = self.target.model(input_ids=inp, past_key_values=t_state.past, use_cache=True)\n",
    "            \n",
    "            pre_top1 = t_state.last_logits.argmax(dim=-1)\n",
    "            if L_hat > 1:\n",
    "                seq_top1 = out.logits[0, :-1].argmax(dim=-1)\n",
    "            else:\n",
    "                seq_top1 = torch.empty(0, device=dev, dtype=torch.long)\n",
    "            \n",
    "            preds = torch.cat([pre_top1.view(1), seq_top1], dim=0)\n",
    "            eq = (preds == toks)\n",
    "            \n",
    "\n",
    "            if eq.all():\n",
    "\n",
    "                new_state = KVState(\n",
    "                    past=out.past_key_values,\n",
    "                    last_logits=out.logits[:, -1, :],\n",
    "                    seq_len=t_state.seq_len + L_hat\n",
    "                )\n",
    "                return True, L_hat, new_state\n",
    "            \n",
    "\n",
    "            L = int(eq.int().cumprod(0).sum().item())\n",
    "            if L == 0:\n",
    "                return False, 0, t_state\n",
    "            \n",
    "\n",
    "            inp2 = toks[:L].unsqueeze(0)\n",
    "            out2 = self.target.model(input_ids=inp2, past_key_values=t_state.past, use_cache=True)\n",
    "            new_state = KVState(\n",
    "                past=out2.past_key_values,\n",
    "                last_logits=out2.logits[:, -1, :],\n",
    "                seq_len=t_state.seq_len + L\n",
    "            )\n",
    "            return False, L, new_state\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features_fast(per_step_logits, drafted_tokens, committed_tail_ids):\n",
    "    \"\"\"Minimal feature extraction for speed\"\"\"\n",
    "    if not per_step_logits:\n",
    "        return torch.zeros(0, dtype=torch.float32)\n",
    "    \n",
    "    dev = per_step_logits[0].device\n",
    "    feats = []\n",
    "    \n",
    "    for logits in per_step_logits:\n",
    "        topv, _ = torch.topk(logits, k=2, dim=-1)\n",
    "        probs = torch.softmax(topv, dim=-1)[0]\n",
    "        \n",
    "        margin = probs[0] - probs[1]\n",
    "        entropy = -(probs * probs.log()).sum()\n",
    "        \n",
    "        feats.extend([margin.item(), entropy.item()])\n",
    "    \n",
    "    return torch.tensor(feats, device=dev, dtype=torch.float32)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features_gpu(per_step_logits, drafted_tokens, committed_tail_ids):\n",
    "    \"\"\"Original 4-feature extraction for compatibility\"\"\"\n",
    "    dev = per_step_logits[0].device\n",
    "    feats = []\n",
    "    recent_tail = committed_tail_ids.to(dev)[0, -RECENT_N:]\n",
    "    drafted = torch.tensor(drafted_tokens, device=dev, dtype=torch.long)\n",
    "    repeat_mask = torch.isin(drafted, recent_tail).float()\n",
    "\n",
    "    for t, logits in enumerate(per_step_logits):\n",
    "        topv, _ = torch.topk(logits, k=min(TOPK, logits.shape[-1]), dim=-1)\n",
    "        logp_top = topv - torch.logsumexp(topv, dim=-1, keepdim=True)\n",
    "        p_top = logp_top.exp()\n",
    "        H_approx = -(p_top * logp_top).sum().float()\n",
    "        p1 = p_top[0,0].float()\n",
    "        p2 = p_top[0,1].float() if p_top.shape[1] > 1 else torch.tensor(0.0, device=dev)\n",
    "        margin = (p1 - p2)\n",
    "        lp_chosen = logp_top[0,0].float()\n",
    "        repeat = repeat_mask[t]\n",
    "        feats.extend([H_approx, margin, lp_chosen, repeat])\n",
    "\n",
    "    return torch.stack(feats).to(torch.float32)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features_gpu_enhanced(per_step_logits, drafted_tokens, committed_tail_ids, topk=TOPK):\n",
    "    \"\"\"Enhanced feature extraction with 10 features per position\"\"\"\n",
    "    if not per_step_logits:\n",
    "        return torch.zeros(0, dtype=torch.float32, device=committed_tail_ids.device if torch.is_tensor(committed_tail_ids) else \"cpu\")\n",
    "\n",
    "    dev = per_step_logits[0].device\n",
    "    dt  = per_step_logits[0].dtype\n",
    "\n",
    "    feats = []\n",
    "    recent_tail = committed_tail_ids.to(dev)[0, -RECENT_N:]\n",
    "    drafted = torch.as_tensor(drafted_tokens, device=dev, dtype=torch.long)\n",
    "    K = len(per_step_logits)\n",
    "\n",
    "    for t, logits in enumerate(per_step_logits):\n",
    "        with monitor.timer(\"feature_extraction_step\"):\n",
    "            k = min(int(topk), logits.shape[-1])\n",
    "            topv, topi = torch.topk(logits, k=k, dim=-1)\n",
    "            logp_top = topv - torch.logsumexp(topv, dim=-1, keepdim=True)\n",
    "            p_top = logp_top.exp()\n",
    "\n",
    "            H_approx = -(p_top * logp_top).sum(dim=-1).squeeze(0).to(dt)\n",
    "            p1 = p_top[0, 0].to(dt)\n",
    "            p2 = p_top[0, 1] if k > 1 else torch.zeros((), device=dev, dtype=dt)\n",
    "            margin = (p1 - p2).clamp(min=0)\n",
    "\n",
    "            chosen_tok = drafted[t] if t < drafted.numel() else topi[0, 0]\n",
    "            full_logp = F.log_softmax(logits, dim=-1)\n",
    "            chosen_tok_clamped = chosen_tok.clamp_(max=full_logp.shape[-1]-1)\n",
    "            lp_chosen = full_logp[0, chosen_tok_clamped].to(dt)\n",
    "\n",
    "            repeat = torch.isin(chosen_tok.view(1), recent_tail).to(dt).squeeze(0)\n",
    "\n",
    "            chosen_logit = logits[0, chosen_tok_clamped]\n",
    "            rank_val = (logits.squeeze(0) > chosen_logit).sum().to(dt) + torch.ones((), device=dev, dtype=dt)\n",
    "            log_rank = torch.log(rank_val + 1)\n",
    "\n",
    "            top5_mass = p_top[0, :min(5, k)].sum().to(dt)\n",
    "            rel_pos = torch.tensor(float(t) / max(1, K), device=dev, dtype=dt)\n",
    "            p_var = (p_top[0].var(unbiased=False) if k > 1 else torch.zeros((), device=dev, dtype=dt))\n",
    "\n",
    "            vocab_size = logits.shape[-1]\n",
    "            uniform_logp = torch.tensor(-math.log(vocab_size), device=dev, dtype=dt)\n",
    "            kl_uniform = (p_top[0] * (logp_top[0] - uniform_logp)).sum().to(dt)\n",
    "\n",
    "            confidence = (p1 * margin).to(dt)\n",
    "\n",
    "            features_t = torch.stack([\n",
    "                H_approx, margin, lp_chosen, repeat, log_rank,\n",
    "                top5_mass, rel_pos, p_var, kl_uniform, confidence\n",
    "            ]).to(torch.float32)\n",
    "\n",
    "            feats.append(features_t)\n",
    "\n",
    "    return torch.cat(feats)\n",
    "\n",
    "@torch.no_grad()\n",
    "def heuristic_L_hat_gpu(per_step_logits, drafted_tokens, committed_ids,\n",
    "                       margin_thresh=0.19, min_keep=2, max_k=None):\n",
    "    k = len(per_step_logits) if max_k is None else min(len(per_step_logits), max_k)\n",
    "    Lh = 0\n",
    "    for t in range(k):\n",
    "        logits = per_step_logits[t]\n",
    "        topv, _ = torch.topk(logits, k=2, dim=-1)\n",
    "        probs2 = torch.softmax(topv, dim=-1)[0]\n",
    "        margin = float(probs2[0] - probs2[1])\n",
    "        if t >= min_keep and margin < margin_thresh:\n",
    "            break\n",
    "        Lh += 1\n",
    "    return Lh\n",
    "\n",
    "class FastVerifierMLP(nn.Module):\n",
    "    def __init__(self, in_dim, kmax):\n",
    "        super().__init__()\n",
    "        h = 128  # Reduced hidden size\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, h),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(h, kmax + 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class AdaptiveController:\n",
    "    def __init__(self, config: AdaptiveConfig):\n",
    "        self.config = config\n",
    "        self.history = deque(maxlen=config.confidence_window)\n",
    "        self.k = config.k_init\n",
    "        self.tau = config.tau_init\n",
    "        self.margin = config.margin_init\n",
    "        self.weak_counter = 0\n",
    "\n",
    "    def update(self, accepted: int, asked: int, confidence: float = 0.5):\n",
    "        self.history.append(accepted)\n",
    "\n",
    "        if accepted >= 0.8 * asked:\n",
    "            self.k = min(self.k + 2, self.config.k_max)\n",
    "            self.weak_counter = 0\n",
    "        elif accepted < 0.3 * asked:\n",
    "            self.k = max(self.config.k_min, self.k // 2)\n",
    "            self.weak_counter += 1\n",
    "\n",
    "        if asked >= 4 and accepted == asked:\n",
    "            self.tau = max(self.config.tau_min, self.tau - self.config.adaptation_rate)\n",
    "            self.margin = max(self.config.margin_min, self.margin - self.config.adaptation_rate)\n",
    "        elif accepted < asked * 0.5:\n",
    "            self.tau = min(self.config.tau_max, self.tau + 2 * self.config.adaptation_rate)\n",
    "            self.margin = min(self.config.margin_max, self.margin + 2 * self.config.adaptation_rate)\n",
    "\n",
    "        if self.weak_counter >= self.config.weak_threshold:\n",
    "            self.tau = min(self.config.tau_max, self.tau + 0.05)\n",
    "            self.margin = min(self.config.margin_max, self.margin + 0.05)\n",
    "            self.weak_counter = 0\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.k, self.tau, self.margin\n",
    "\n",
    "print(f\"Parallel speculation components loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ab3c6-4454-42bb-b207-875d4a43c51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Parallel runtime loaded\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 3: Fixed Main Runtime with Pipelining =====\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_parallel_vspec(prompt: str, \n",
    "                       max_new: int = 256,\n",
    "                       k_base: int = 8,\n",
    "                       adaptive: bool = True,\n",
    "                       verbose: bool = False):\n",
    "    tok = target.tok\n",
    "    t_inp = tok(prompt, return_tensors=\"pt\").to(target.device)[\"input_ids\"]\n",
    "    d_inp = tok(prompt, return_tensors=\"pt\").to(drafter.device)[\"input_ids\"]\n",
    "\n",
    "    t_state = init_state(target, t_inp)\n",
    "    d_state = init_state(drafter, d_inp)\n",
    "    \n",
    "    committed_ids = t_inp.clone()\n",
    "    committed_len = 0\n",
    "    \n",
    "\n",
    "    speculator = PipelinedSpeculator(target, drafter, stream_mgr)\n",
    "\n",
    "    k = k_base\n",
    "    accept_history = deque(maxlen=10)\n",
    "    controller = AdaptiveController(CONFIG) if adaptive else None\n",
    "    \n",
    "    # Stats\n",
    "    stats = {\n",
    "        'target_calls': 0,\n",
    "        'drafter_calls': 0,\n",
    "        'blocks': 0,\n",
    "        'total_accepted': 0,\n",
    "        'total_asked': 0\n",
    "    }\n",
    "    \n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "\n",
    "    pending_draft = None\n",
    "    pending_verify = None\n",
    "    \n",
    "    while committed_len < max_new:\n",
    "        if pending_draft is None:\n",
    "            if adaptive and controller:\n",
    "                k, _, _ = controller.get_params()\n",
    "            elif adaptive and len(accept_history) >= 3:\n",
    "                recent_rate = sum(accept_history) / len(accept_history)\n",
    "                if recent_rate > 0.7:\n",
    "                    k = min(k + 1, CONFIG.k_max)\n",
    "                elif recent_rate < 0.3:\n",
    "                    k = max(k - 1, CONFIG.k_min)\n",
    "            \n",
    "            draft_future = speculator.draft_async(d_state, k)\n",
    "            stats['drafter_calls'] += 1\n",
    "            pending_draft = (draft_future, k)\n",
    "        \n",
    "        if pending_verify is not None:\n",
    "            stream_mgr.target_stream.synchronize()\n",
    "            ok, accepted, t_state_new = pending_verify\n",
    "            \n",
    "            if accepted > 0:\n",
    "                draft_tokens = pending_verify_tokens[:accepted]\n",
    "                committed_ids = torch.cat([\n",
    "                    committed_ids,\n",
    "                    torch.tensor([draft_tokens], device=committed_ids.device)\n",
    "                ], dim=1)\n",
    "                committed_len += accepted\n",
    "                t_state = t_state_new\n",
    "                \n",
    "                for tok_id in draft_tokens:\n",
    "                    inp = torch.tensor([[tok_id]], device=d_state.last_logits.device, dtype=torch.long)\n",
    "                    out = drafter.model(input_ids=inp, past_key_values=d_state.past, use_cache=True)\n",
    "                    d_state = KVState(\n",
    "                        past=out.past_key_values,\n",
    "                        last_logits=out.logits[:, -1, :],\n",
    "                        seq_len=d_state.seq_len + 1\n",
    "                    )\n",
    "                \n",
    "                stats['total_accepted'] += accepted\n",
    "                accept_history.append(accepted / pending_verify_L)\n",
    "                if controller:\n",
    "                    controller.update(accepted, pending_verify_L, 0.5)\n",
    "            else:\n",
    "                next_id = int(t_state.last_logits.argmax(-1).item())\n",
    "                inp_t = torch.tensor([[next_id]], device=t_state.last_logits.device, dtype=torch.long)\n",
    "                inp_d = torch.tensor([[next_id]], device=d_state.last_logits.device, dtype=torch.long)\n",
    "                \n",
    "                out_t = target.model(input_ids=inp_t, past_key_values=t_state.past, use_cache=True)\n",
    "                t_state = KVState(\n",
    "                    past=out_t.past_key_values,\n",
    "                    last_logits=out_t.logits[:, -1, :],\n",
    "                    seq_len=t_state.seq_len + 1\n",
    "                )\n",
    "                \n",
    "                out_d = drafter.model(input_ids=inp_d, past_key_values=d_state.past, use_cache=True)\n",
    "                d_state = KVState(\n",
    "                    past=out_d.past_key_values,\n",
    "                    last_logits=out_d.logits[:, -1, :],\n",
    "                    seq_len=d_state.seq_len + 1\n",
    "                )\n",
    "                \n",
    "                committed_ids = torch.cat([\n",
    "                    committed_ids,\n",
    "                    inp_t.to(committed_ids.device)\n",
    "                ], dim=1)\n",
    "                committed_len += 1\n",
    "                \n",
    "                accept_history.append(0)\n",
    "                if controller:\n",
    "                    controller.update(0, pending_verify_L, 0.5)\n",
    "            \n",
    "            pending_verify = None\n",
    "        \n",
    "        if pending_draft is not None and pending_verify is None:\n",
    "            stream_mgr.drafter_stream.synchronize()\n",
    "            draft_tokens, draft_logits, d_state_new = pending_draft[0]\n",
    "            \n",
    "            L_hat = min(len(draft_tokens), k)\n",
    "            \n",
    "            margins = []\n",
    "            for logits in draft_logits[:L_hat]:\n",
    "                topv, _ = torch.topk(logits, k=2, dim=-1)\n",
    "                probs = torch.softmax(topv, dim=-1)[0]\n",
    "                margins.append((probs[0] - probs[1]).item())\n",
    "            \n",
    "            margin_thresh = controller.margin if controller else CONFIG.margin_init\n",
    "            for i, margin in enumerate(margins):\n",
    "                if i >= 2 and margin < margin_thresh:\n",
    "                    L_hat = i\n",
    "                    break\n",
    "            \n",
    "            L_hat = max(1, L_hat)\n",
    "            stats['total_asked'] += L_hat\n",
    "            stats['blocks'] += 1\n",
    "            \n",
    "            verify_result = speculator.verify_async(t_state, draft_tokens, L_hat)\n",
    "            stats['target_calls'] += 1\n",
    "            \n",
    "            pending_verify = verify_result\n",
    "            pending_verify_tokens = draft_tokens\n",
    "            pending_verify_L = L_hat\n",
    "            \n",
    "            d_state = d_state_new\n",
    "            pending_draft = None\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    \n",
    "    stats['tokens_per_sec'] = committed_len / max(elapsed, 1e-6)\n",
    "    stats['mean_accept'] = stats['total_accepted'] / max(1, stats['blocks'])\n",
    "    stats['accept_rate'] = stats['total_accepted'] / max(1, stats['total_asked'])\n",
    "    stats['time'] = elapsed\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n=== Parallel V-Spec Results ===\")\n",
    "        print(f\"Tokens/sec: {stats['tokens_per_sec']:.2f}\")\n",
    "        print(f\"Mean accept: {stats['mean_accept']:.2f}\")\n",
    "        print(f\"Accept rate: {stats['accept_rate']:.2%}\")\n",
    "        print(f\"Target calls: {stats['target_calls']}\")\n",
    "        print(f\"Drafter calls: {stats['drafter_calls']}\")\n",
    "        print(f\"Time: {stats['time']:.2f}s\")\n",
    "    \n",
    "    monitor.reset()\n",
    "    \n",
    "    return tok.decode(committed_ids[0].tolist()), stats\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_greedy_optimized(prompt, max_new=256):\n",
    "    tok = target.tok\n",
    "    inp = tok(prompt, return_tensors=\"pt\").to(target.device)[\"input_ids\"]\n",
    "    \n",
    "    past = None\n",
    "    input_ids = inp\n",
    "    \n",
    "    t0 = time.perf_counter()\n",
    "    \n",
    "    for _ in range(max_new):\n",
    "        if past is not None:\n",
    "            out = target.model(input_ids=input_ids[:, -1:], past_key_values=past, use_cache=True)\n",
    "        else:\n",
    "            out = target.model(input_ids=input_ids, use_cache=True)\n",
    "        \n",
    "        next_id = out.logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "        input_ids = torch.cat([input_ids, next_id], dim=1)\n",
    "        past = out.past_key_values\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    elapsed = time.perf_counter() - t0\n",
    "    \n",
    "    return {\n",
    "        \"tokens_per_s\": max_new / max(elapsed, 1e-6),\n",
    "        \"tgt_calls\": max_new,\n",
    "        \"time\": elapsed\n",
    "    }\n",
    "\n",
    "def run_greedy_cached(prompt, max_new=256):\n",
    "    return run_greedy_optimized(prompt, max_new)\n",
    "\n",
    "def run_spec_block(prompt, k=8, max_new=256):\n",
    "    _, stats = run_parallel_vspec(prompt, max_new=max_new, k_base=k, adaptive=False, verbose=False)\n",
    "    return {\n",
    "        \"tokens_per_s\": stats['tokens_per_sec'],\n",
    "        \"tgt_calls\": stats['target_calls'],\n",
    "        \"d_calls\": stats['drafter_calls'],\n",
    "        \"time\": stats['time'],\n",
    "        \"blocks\": stats['blocks'],\n",
    "        \"mean_accept\": stats['mean_accept']\n",
    "    }\n",
    "\n",
    "def run_enhanced_vspec(prompt: str,\n",
    "                       max_new: int = 256,\n",
    "                       use_tree: bool = True,  \n",
    "                       use_cascade: bool = True,  \n",
    "                       verbose: bool = False):\n",
    "    return run_parallel_vspec(prompt, max_new=max_new, k_base=8, adaptive=True, verbose=verbose)\n",
    "\n",
    "print(\"Parallel runtime loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f98e9c-f3fa-4ff2-a11b-2caa3cd6f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing dataset...\n",
      "Loaded 12000 training samples\n",
      "Dataset info: K_TRAIN=14, features_per_pos=4\n",
      "Enhanced dataset shape: (12000, 140)\n",
      "Original dataset shape: (12000, 56)\n",
      "\n",
      "Training on device: cuda:1\n",
      "\n",
      "1. Training baseline MLP on original features...\n",
      "Epoch 0: train_loss=1.2503, val_loss=0.8495, val_acc=0.7808\n",
      "Epoch 5: train_loss=0.7886, val_loss=0.7129, val_acc=0.7792\n",
      "Epoch 10: train_loss=0.7319, val_loss=0.6812, val_acc=0.7808\n",
      "Early stopping at epoch 14\n",
      "\n",
      "2. Training enhanced MLP on enhanced features...\n",
      "Epoch 0: train_loss=1.1509, val_loss=0.8420, val_acc=0.7808\n",
      "Epoch 5: train_loss=0.7883, val_loss=0.6943, val_acc=0.7858\n",
      "Epoch 10: train_loss=0.7100, val_loss=0.6892, val_acc=0.7900\n",
      "Early stopping at epoch 10\n",
      "\n",
      "3. Training CNN verifier...\n",
      "Epoch 0: train_loss=1.5665, val_loss=1.0367, val_acc=0.7808\n",
      "Epoch 5: train_loss=0.9733, val_loss=0.8837, val_acc=0.7808\n",
      "Epoch 10: train_loss=0.9305, val_loss=0.8328, val_acc=0.7808\n",
      "\n",
      "4. Training Transformer verifier...\n",
      "Epoch 0: train_loss=1.0971, val_loss=0.8988, val_acc=0.7808\n",
      "Epoch 5: train_loss=0.8591, val_loss=0.7460, val_acc=0.7817\n",
      "Epoch 10: train_loss=0.7989, val_loss=0.7067, val_acc=0.7933\n",
      "\n",
      "5. Creating cascade verifier...\n",
      "\n",
      "Saving models...\n",
      "✓ Saved enhanced verifiers to /workspace/vspec/ckpt/vspec_verifier_enhanced.pt\n",
      "\n",
      "=== Test Set Performance ===\n",
      "MLP Baseline: Accuracy=0.7717\n",
      "MLP Enhanced: Accuracy=0.7733, Avg Confidence=0.7002\n",
      "CNN: Accuracy=0.7533\n",
      "Transformer: Accuracy=0.7742\n",
      "\n",
      "✓ Training complete!\n",
      "Models saved to: /workspace/vspec/ckpt/vspec_verifier_enhanced.pt\n"
     ]
    }
   ],
   "source": [
    "import json, numpy as np, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "print(\"Loading existing dataset...\")\n",
    "rows = [json.loads(l) for l in open(os.environ[\"DATA_PATH\"])]\n",
    "print(f\"Loaded {len(rows)} training samples\")\n",
    "\n",
    "\n",
    "K_TRAIN = max(r[\"k\"] for r in rows)\n",
    "fpps = [len(r[\"features\"]) // max(1, r[\"k\"]) for r in rows if r[\"k\"] > 0]\n",
    "FEAT_PER_POS_EXISTING = max(set(fpps), key=fpps.count) if fpps else 4\n",
    "\n",
    "print(f\"Dataset info: K_TRAIN={K_TRAIN}, features_per_pos={FEAT_PER_POS_EXISTING}\")\n",
    "\n",
    "\n",
    "def enhance_features_from_existing(features_list, k_val, target_feat_dim=10):\n",
    "    n_pos = k_val\n",
    "    if len(features_list) < n_pos * 4:\n",
    "        features_list = features_list + [0.0] * (n_pos * 4 - len(features_list))\n",
    "\n",
    "    enhanced = []\n",
    "    for pos in range(n_pos):\n",
    "        idx = pos * 4\n",
    "        if idx + 3 < len(features_list):\n",
    "            entropy = features_list[idx]\n",
    "            margin  = features_list[idx + 1]\n",
    "            logp    = features_list[idx + 2]\n",
    "            repeat  = features_list[idx + 3]\n",
    "\n",
    "\n",
    "            rank_est   = np.exp(-logp) * 10\n",
    "            top5_mass  = min(1.0, margin + 0.3)\n",
    "            rel_pos    = pos / max(1, n_pos)\n",
    "            variance   = entropy * 0.1\n",
    "            kl_uniform = max(0, 1 - entropy)\n",
    "            confidence = margin * np.exp(logp)\n",
    "\n",
    "            enhanced.extend([\n",
    "                entropy, margin, logp, repeat,\n",
    "                np.log(rank_est + 1), top5_mass, rel_pos,\n",
    "                variance, kl_uniform, confidence\n",
    "            ])\n",
    "        else:\n",
    "            enhanced.extend([0.0] * 10)\n",
    "    return enhanced\n",
    "\n",
    "def prepare_enhanced_dataset(rows, use_enhancement=True):\n",
    "    if use_enhancement:\n",
    "        feat_dim = K_TRAIN * 10\n",
    "        X = []\n",
    "        for r in rows:\n",
    "            enhanced = enhance_features_from_existing(r[\"features\"], r[\"k\"])\n",
    "            if len(enhanced) < feat_dim:\n",
    "                enhanced = enhanced + [0.0] * (feat_dim - len(enhanced))\n",
    "            else:\n",
    "                enhanced = enhanced[:feat_dim]\n",
    "            X.append(enhanced)\n",
    "        X = np.array(X, dtype=np.float32)\n",
    "    else:\n",
    "        feat_dim = K_TRAIN * FEAT_PER_POS_EXISTING\n",
    "        X = []\n",
    "        for r in rows:\n",
    "            f = r[\"features\"]\n",
    "            if len(f) < feat_dim:\n",
    "                f = f + [0.0] * (feat_dim - len(f))\n",
    "            else:\n",
    "                f = f[:feat_dim]\n",
    "            X.append(f)\n",
    "        X = np.array(X, dtype=np.float32)\n",
    "\n",
    "\n",
    "    y = np.array([min(int(r[\"L\"]), K_TRAIN) for r in rows], dtype=np.int64)\n",
    "    return X, y, feat_dim\n",
    "\n",
    "X_enhanced, y, feat_dim_enhanced = prepare_enhanced_dataset(rows, use_enhancement=True)\n",
    "X_original, _, feat_dim_original = prepare_enhanced_dataset(rows, use_enhancement=False)\n",
    "\n",
    "print(f\"Enhanced dataset shape: {X_enhanced.shape}\")\n",
    "print(f\"Original dataset shape: {X_original.shape}\")\n",
    "\n",
    "class VSpecDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)         \n",
    "        self.y = torch.from_numpy(y)        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "n = len(X_enhanced)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "n_test  = n - n_train - n_val\n",
    "\n",
    "dataset_enhanced = VSpecDataset(X_enhanced, y)\n",
    "dataset_original = VSpecDataset(X_original, y)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_idx, val_idx, test_idx = random_split(range(n), [n_train, n_val, n_test])\n",
    "\n",
    "def get_loaders(dataset, batch_size=256):\n",
    "    train_set = torch.utils.data.Subset(dataset, train_idx.indices)\n",
    "    val_set   = torch.utils.data.Subset(dataset, val_idx.indices)\n",
    "    test_set  = torch.utils.data.Subset(dataset, test_idx.indices)\n",
    "    pin = torch.cuda.is_available()\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,  pin_memory=pin)\n",
    "    val_loader   = DataLoader(val_set,   batch_size=batch_size, shuffle=False, pin_memory=pin)\n",
    "    test_loader  = DataLoader(test_set,  batch_size=batch_size, shuffle=False, pin_memory=pin)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "N_CLASSES = K_TRAIN + 1  \n",
    "\n",
    "class SimpleVerifierMLP(nn.Module):\n",
    "    def __init__(self, in_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 512), nn.GELU(), nn.Dropout(0.1),\n",
    "            nn.Linear(512, 256),    nn.GELU(), nn.Dropout(0.1),\n",
    "        )\n",
    "        self.head = nn.Linear(256, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        h = self.net(x)               \n",
    "        logits = self.head(h)\n",
    "        return logits                 # shape [B, n_classes], requires_grad=True\n",
    "\n",
    "class VerifierMLP(nn.Module):\n",
    "    def __init__(self, in_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, 1024), nn.GELU(), nn.Dropout(0.1),\n",
    "            nn.Linear(1024, 512),    nn.GELU(), nn.Dropout(0.1),\n",
    "            nn.Linear(512, 256),     nn.GELU(), nn.Dropout(0.1),\n",
    "        )\n",
    "        self.cls_head  = nn.Linear(256, n_classes)\n",
    "        self.conf_head = nn.Sequential(nn.Linear(256, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        h = self.encoder(x)\n",
    "        logits = self.cls_head(h)\n",
    "        conf   = self.conf_head(h).squeeze(-1)\n",
    "        return logits, conf\n",
    "\n",
    "class VerifierCNN(nn.Module):\n",
    "    def __init__(self, in_dim, n_classes, feat_per_pos=10):\n",
    "        super().__init__()\n",
    "        self.k = K_TRAIN\n",
    "        self.f = feat_per_pos\n",
    "        assert in_dim == self.k * self.f\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(self.f, 64, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "        )\n",
    "        self.head = nn.Linear(128, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32).view(x.size(0), self.k, self.f)   # [B, K, F]\n",
    "        x = x.permute(0, 2, 1)                                    # [B, F, K]\n",
    "        h = self.conv(x).squeeze(-1)                              # [B, 128]\n",
    "        logits = self.head(h)\n",
    "        return logits\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1024):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "class VerifierTransformer(nn.Module):\n",
    "    def __init__(self, in_dim, n_classes, feat_per_pos=10, hidden_dim=128, n_heads=4, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.k = K_TRAIN\n",
    "        self.f = feat_per_pos\n",
    "        assert in_dim == self.k * self.f\n",
    "        self.proj = nn.Linear(self.f, hidden_dim)\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, nhead=n_heads, batch_first=True,\n",
    "            dim_feedforward=hidden_dim*4, activation='gelu'\n",
    "        )\n",
    "        self.enc = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n",
    "        self.pos = PositionalEncoding(hidden_dim, max_len=self.k+1)\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, hidden_dim))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "        self.head = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        x = x.to(torch.float32).view(B, self.k, self.f)     # [B, K, F]\n",
    "        h = self.proj(x)                                    # [B, K, H]\n",
    "        cls = self.cls.expand(B, 1, -1)                     # [B, 1, H]\n",
    "        h = torch.cat([cls, h], dim=1)                      # [B, K+1, H]\n",
    "        h = self.pos(h)\n",
    "        h = self.enc(h)\n",
    "        cls_h = h[:, 0, :]                                  # [B, H]\n",
    "        logits = self.head(cls_h)\n",
    "        return logits\n",
    "\n",
    "class CascadeVerifier(nn.Module):\n",
    "    def __init__(self, verifiers, thresholds):\n",
    "        super().__init__()\n",
    "        assert len(verifiers) == len(thresholds)\n",
    "        self.verifiers  = nn.ModuleList(verifiers)\n",
    "        self.thresholds = thresholds\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        for ver, th in zip(self.verifiers, self.thresholds):\n",
    "            out = ver(x)\n",
    "            if isinstance(out, tuple):\n",
    "                logits, conf = out\n",
    "                mask = conf >= th\n",
    "            else:\n",
    "                logits = out\n",
    "                mask = logits.softmax(-1).max(dim=-1).values >= th\n",
    "            if mask.all():\n",
    "                return logits\n",
    "        return logits  \n",
    "\n",
    "def train_verifier(model, train_loader, val_loader, device, epochs=20, patience=3):\n",
    "    model = model.to(device)\n",
    "    assert any(p.requires_grad for p in model.parameters()), \"No trainable parameters in model\"\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                out = model(xb)\n",
    "                if isinstance(out, tuple):\n",
    "                    logits, conf = out\n",
    "                    loss = criterion(logits, yb)\n",
    "                    conf_reg = 0.01 * (conf.mean() - 0.7).abs()\n",
    "                    total_loss = loss + conf_reg\n",
    "                else:\n",
    "                    logits = out\n",
    "                    total_loss = criterion(logits, yb)\n",
    "\n",
    "                # Gradient sanity checks\n",
    "                if not isinstance(total_loss, torch.Tensor):\n",
    "                    raise RuntimeError(\"Loss became a Python float; ensure model returns tensors.\")\n",
    "                if not total_loss.requires_grad:\n",
    "                    raise RuntimeError(\"Loss has no grad_fn; check for .detach() in model forward.\")\n",
    "\n",
    "                total_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += total_loss.detach().item() * xb.size(0)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device, non_blocking=True)\n",
    "                yb = yb.to(device, non_blocking=True)\n",
    "                out = model(xb)\n",
    "                logits = out[0] if isinstance(out, tuple) else out\n",
    "                loss = criterion(logits, yb)\n",
    "                val_loss += loss.item() * xb.size(0)\n",
    "                pred = logits.argmax(dim=1)\n",
    "                correct += (pred == yb).sum().item()\n",
    "                total += yb.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = correct / total\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model, history\n",
    "\n",
    "device = torch.device(TARGET_DEV if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nTraining on device: {device}\")\n",
    "\n",
    "train_loader_enh, val_loader_enh, test_loader_enh = get_loaders(dataset_enhanced)\n",
    "train_loader_orig, val_loader_orig, test_loader_orig = get_loaders(dataset_original)\n",
    "\n",
    "print(\"\\n1. Training baseline MLP on original features...\")\n",
    "mlp_baseline = SimpleVerifierMLP(feat_dim_original, N_CLASSES)\n",
    "mlp_baseline, hist_baseline = train_verifier(\n",
    "    mlp_baseline, train_loader_orig, val_loader_orig, device, epochs=15\n",
    ")\n",
    "\n",
    "print(\"\\n2. Training enhanced MLP on enhanced features...\")\n",
    "mlp_enhanced = VerifierMLP(feat_dim_enhanced, N_CLASSES)\n",
    "mlp_enhanced, hist_mlp = train_verifier(\n",
    "    mlp_enhanced, train_loader_enh, val_loader_enh, device, epochs=15\n",
    ")\n",
    "\n",
    "print(\"\\n3. Training CNN verifier...\")\n",
    "cnn_verifier = VerifierCNN(feat_dim_enhanced, N_CLASSES, feat_per_pos=10)\n",
    "cnn_verifier, hist_cnn = train_verifier(\n",
    "    cnn_verifier, train_loader_enh, val_loader_enh, device, epochs=15\n",
    ")\n",
    "\n",
    "print(\"\\n4. Training Transformer verifier...\")\n",
    "transformer_verifier = VerifierTransformer(\n",
    "    feat_dim_enhanced, N_CLASSES, feat_per_pos=10,\n",
    "    hidden_dim=128, n_heads=4, n_layers=2\n",
    ")\n",
    "transformer_verifier, hist_trans = train_verifier(\n",
    "    transformer_verifier, train_loader_enh, val_loader_enh, device, epochs=15\n",
    ")\n",
    "\n",
    "print(\"\\n5. Creating cascade verifier...\")\n",
    "cascade = CascadeVerifier(\n",
    "    verifiers=[mlp_enhanced, cnn_verifier, transformer_verifier],\n",
    "    thresholds=[0.7, 0.8, 0.9]\n",
    ")\n",
    "\n",
    "print(\"\\nSaving models...\")\n",
    "torch.save({\n",
    "    'mlp_baseline': mlp_baseline.state_dict(),\n",
    "    'mlp_enhanced': mlp_enhanced.state_dict(),\n",
    "    'cnn': cnn_verifier.state_dict(),\n",
    "    'transformer': transformer_verifier.state_dict(),\n",
    "    'K_TRAIN': K_TRAIN,\n",
    "    'N_CLASSES': N_CLASSES,\n",
    "    'feat_dim_original': feat_dim_original,\n",
    "    'feat_dim_enhanced': feat_dim_enhanced\n",
    "}, os.environ[\"ENHANCED_VERIFIER_PATH\"])\n",
    "print(f\"✓ Saved enhanced verifiers to {os.environ['ENHANCED_VERIFIER_PATH']}\")\n",
    "\n",
    "def evaluate_verifier(model, test_loader, device, name=\"Model\"):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    confidence_sum = 0.0\n",
    "    has_confidence = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            out = model(xb)\n",
    "            if isinstance(out, tuple):\n",
    "                logits, conf = out\n",
    "                has_confidence = True\n",
    "                confidence_sum += conf.sum().item()\n",
    "            else:\n",
    "                logits = out\n",
    "            pred = logits.argmax(dim=1)\n",
    "            correct += (pred == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    if has_confidence:\n",
    "        avg_conf = confidence_sum / total\n",
    "        print(f\"{name}: Accuracy={acc:.4f}, Avg Confidence={avg_conf:.4f}\")\n",
    "    else:\n",
    "        print(f\"{name}: Accuracy={acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "print(\"\\n=== Test Set Performance ===\")\n",
    "evaluate_verifier(mlp_baseline, test_loader_orig, device, \"MLP Baseline\")\n",
    "evaluate_verifier(mlp_enhanced, test_loader_enh, device, \"MLP Enhanced\")\n",
    "evaluate_verifier(cnn_verifier,  test_loader_enh, device, \"CNN\")\n",
    "evaluate_verifier(transformer_verifier, test_loader_enh, device, \"Transformer\")\n",
    "\n",
    "print(\"\\n✓ Training complete!\")\n",
    "print(f\"Models saved to: {os.environ['ENHANCED_VERIFIER_PATH']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c040513-041e-402d-8f5a-4087fe169b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tree-based speculation loaded\n",
      "  Features: Multi-path exploration, batch verification\n",
      "  Tree drafting with branching factor control\n",
      "  Lookahead tree structure for advanced speculation\n",
      "  Block-wise KV cache advancement\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def drafter_draft_tree(drafter_bundle: ModelBundle, d_state: KVState, \n",
    "                      k: int, branching_factor: int = 2, \n",
    "                      temperature: float = 0.0):\n",
    "\n",
    "   if branching_factor == 1 or temperature == 0:\n",
    "       tokens, logits_list, state = drafter_draft_chunk_cached(\n",
    "           drafter_bundle, d_state, k\n",
    "       )\n",
    "       return tokens, logits_list, state, 1.0\n",
    "   \n",
    "   trees = []\n",
    "   dev = d_state.last_logits.device\n",
    "\n",
    "   if temperature > 0:\n",
    "       probs = torch.softmax(d_state.last_logits / temperature, dim=-1)\n",
    "       root_topk = torch.topk(probs, min(branching_factor, probs.shape[-1]))\n",
    "   else:\n",
    "       root_topk = torch.topk(d_state.last_logits, min(branching_factor, d_state.last_logits.shape[-1]))\n",
    "   \n",
    "   for branch_idx in range(root_topk.indices.shape[-1]):\n",
    "       branch_tokens = []\n",
    "       branch_logits = []\n",
    "       branch_probs = []\n",
    "       branch_state = d_state\n",
    "       \n",
    "       first_token = int(root_topk.indices[0, branch_idx].item())\n",
    "       branch_tokens.append(first_token)\n",
    "       branch_logits.append(d_state.last_logits)\n",
    "       branch_probs.append(float(torch.softmax(d_state.last_logits, dim=-1)[0, first_token].item()))\n",
    "       \n",
    "       _, branch_state = greedy_step_with_cache(drafter_bundle, branch_state, first_token)\n",
    "       \n",
    "       for _ in range(k - 1):\n",
    "           next_probs = torch.softmax(branch_state.last_logits, dim=-1)\n",
    "           next_id = int(branch_state.last_logits.argmax(-1).item())\n",
    "           \n",
    "           branch_logits.append(branch_state.last_logits)\n",
    "           branch_probs.append(float(next_probs[0, next_id].item()))\n",
    "           \n",
    "           _, branch_state = greedy_step_with_cache(drafter_bundle, branch_state, next_id)\n",
    "           branch_tokens.append(next_id)\n",
    "       \n",
    "       score = np.prod(branch_probs) ** (1.0 / len(branch_probs))\n",
    "       \n",
    "       trees.append({\n",
    "           'tokens': branch_tokens,\n",
    "           'logits': branch_logits,\n",
    "           'state': branch_state,\n",
    "           'score': score,\n",
    "           'probs': branch_probs\n",
    "       })\n",
    "   \n",
    "   best_tree = max(trees, key=lambda t: t['score'])\n",
    "   \n",
    "   return best_tree['tokens'], best_tree['logits'], best_tree['state'], best_tree['score']\n",
    "\n",
    "@torch.no_grad()\n",
    "def target_verify_batch_paths(target_bundle: ModelBundle, t_state: KVState,\n",
    "                             draft_paths: List[List[int]], max_len: int):\n",
    "   \"\"\"\n",
    "   Verify multiple draft paths in parallel.\n",
    "   Returns list of (accepted_length, final_state) for each path.\n",
    "   \"\"\"\n",
    "   if len(draft_paths) == 1:\n",
    "       from_original = target_verify_block_once(\n",
    "           target_bundle, t_state, draft_paths[0], max_len\n",
    "       )\n",
    "       return [(from_original[1], from_original[2])]\n",
    "   \n",
    "   results = []\n",
    "   for path in draft_paths:\n",
    "       ok, accepted, new_state = target_verify_block_once(\n",
    "           target_bundle, t_state, path[:max_len], max_len\n",
    "       )\n",
    "       results.append((accepted, new_state))\n",
    "   \n",
    "   return results\n",
    "\n",
    "@torch.no_grad()\n",
    "def target_verify_block_once(target: ModelBundle, t_state_start: KVState,\n",
    "                            draft_tokens: List[int], upto_L: int) -> Tuple[bool, int, KVState]:\n",
    "   with monitor.timer(\"verify_block\"):\n",
    "       if upto_L <= 0:\n",
    "           return False, 0, t_state_start\n",
    "       \n",
    "       dev = t_state_start.last_logits.device\n",
    "       toks = torch.as_tensor(draft_tokens[:upto_L], device=dev, dtype=torch.long)\n",
    "       inp = toks.unsqueeze(0)\n",
    "       \n",
    "       with torch.cuda.amp.autocast(enabled=True, dtype=torch.bfloat16):\n",
    "           out = target.model(input_ids=inp, past_key_values=t_state_start.past, use_cache=True)\n",
    "       \n",
    "       pre_top1 = t_state_start.last_logits.argmax(dim=-1)\n",
    "       seq_top1 = out.logits[0, :-1].argmax(dim=-1) if upto_L > 1 else torch.empty(0, device=dev, dtype=torch.long)\n",
    "       preds = torch.cat([pre_top1.view(1), seq_top1], dim=0)\n",
    "       eq = (preds == toks)\n",
    "       \n",
    "       if bool(eq.all().item()):\n",
    "           new_state = KVState(\n",
    "               past=getattr(out, \"past_key_values\", None),\n",
    "               last_logits=out.logits[:, -1, :],\n",
    "               seq_len=t_state_start.seq_len + upto_L\n",
    "           )\n",
    "           return True, upto_L, new_state\n",
    "       \n",
    "       L = int(eq.int().cumprod(0).sum().item())\n",
    "       if L == 0:\n",
    "           return False, 0, t_state_start\n",
    "       \n",
    "       inp2 = toks[:L].unsqueeze(0)\n",
    "       with torch.cuda.amp.autocast(enabled=True, dtype=torch.bfloat16):\n",
    "           out2 = target.model(input_ids=inp2, past_key_values=t_state_start.past, use_cache=True)\n",
    "       \n",
    "       new_state = KVState(\n",
    "           past=getattr(out2, \"past_key_values\", None),\n",
    "           last_logits=out2.logits[:, -1, :],\n",
    "           seq_len=t_state_start.seq_len + L\n",
    "       )\n",
    "       return False, L, new_state\n",
    "\n",
    "class LookaheadTree:\n",
    "   def __init__(self, max_depth=10, max_width=3):\n",
    "       self.max_depth = max_depth\n",
    "       self.max_width = max_width\n",
    "       self.nodes = []\n",
    "   \n",
    "   def build_tree(self, drafter_bundle: ModelBundle, state: KVState, depth: int):\n",
    "       if depth == 0:\n",
    "           return []\n",
    "       \n",
    "       probs = torch.softmax(state.last_logits, dim=-1)\n",
    "       topk = torch.topk(probs, min(self.max_width, probs.shape[-1]))\n",
    "       \n",
    "       branches = []\n",
    "       for i in range(topk.indices.shape[-1]):\n",
    "           token = int(topk.indices[0, i].item())\n",
    "           prob = float(topk.values[0, i].item())\n",
    "           \n",
    "           _, new_state = greedy_step_with_cache(drafter_bundle, state, token)\n",
    "           \n",
    "           subtree = self.build_tree(drafter_bundle, new_state, depth - 1)\n",
    "           \n",
    "           branches.append({\n",
    "               'token': token,\n",
    "               'prob': prob,\n",
    "               'state': new_state,\n",
    "               'children': subtree\n",
    "           })\n",
    "       \n",
    "       return branches\n",
    "   \n",
    "   def get_best_path(self, tree, accumulated_prob=1.0):\n",
    "       if not tree:\n",
    "           return [], 0\n",
    "       \n",
    "       best_path = []\n",
    "       best_score = 0\n",
    "       \n",
    "       for branch in tree:\n",
    "           current_prob = accumulated_prob * branch['prob']\n",
    "           \n",
    "           sub_path, sub_score = self.get_best_path(branch['children'], current_prob)\n",
    "           \n",
    "           path = [branch['token']] + sub_path\n",
    "           score = current_prob * (1 + len(sub_path))  \n",
    "           \n",
    "           if score > best_score:\n",
    "               best_path = path\n",
    "               best_score = score\n",
    "       \n",
    "       return best_path, best_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def advance_state_block(bundle: ModelBundle, state: KVState, tokens) -> KVState:\n",
    "   if tokens is None or len(tokens) == 0:\n",
    "       return state\n",
    "   \n",
    "   dev = state.last_logits.device\n",
    "   if isinstance(tokens, list):\n",
    "       inp = torch.tensor([tokens], device=dev, dtype=torch.long)\n",
    "   else:\n",
    "       inp = tokens.to(dev, non_blocking=True)\n",
    "       if inp.ndim == 1:\n",
    "           inp = inp.unsqueeze(0)\n",
    "   \n",
    "   out = bundle.model(input_ids=inp, past_key_values=state.past, use_cache=True)\n",
    "   return KVState(\n",
    "       past=getattr(out, \"past_key_values\", None),\n",
    "       last_logits=out.logits[:, -1, :],\n",
    "       seq_len=state.seq_len + inp.shape[1]\n",
    "   )\n",
    "\n",
    "@torch.no_grad()\n",
    "def first_token_match(t_state: KVState, d_state: KVState) -> bool:\n",
    "   t_id = int(t_state.last_logits.argmax(dim=-1).item())\n",
    "   d_id = int(d_state.last_logits.argmax(dim=-1).item())\n",
    "   return t_id == d_id\n",
    "\n",
    "print(\"Tree-based speculation loaded\")\n",
    "print(f\"  Features: Multi-path exploration, batch verification\")\n",
    "print(f\"  Tree drafting with branching factor control\")\n",
    "print(f\"  Lookahead tree structure for advanced speculation\")\n",
    "print(f\"  Block-wise KV cache advancement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f5090-6e90-4ead-a189-57dcc5ed15a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading enhanced verifiers...\n",
      "Checkpoint: K_TRAIN=14, N_CLASSES=15, feat_dim_enhanced=140\n",
      "✓ Loaded verifiers and cascade\n",
      "✓ Enhanced runtime loaded\n",
      "  Features: Tree speculation, cascade verification, adaptive control\n",
      "  Ready to run with run_enhanced_vspec()\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading enhanced verifiers...\")\n",
    "device = torch.device(TARGET_DEV if torch.cuda.is_available() else \"cpu\")\n",
    "ckpt = torch.load(os.environ[\"ENHANCED_VERIFIER_PATH\"], map_location=device)\n",
    "\n",
    "K_TRAIN = int(ckpt[\"K_TRAIN\"])\n",
    "N_CLASSES = int(ckpt.get(\"N_CLASSES\", K_TRAIN + 1))   # fallback for older ckpts\n",
    "EXP_IN = int(ckpt[\"feat_dim_enhanced\"])\n",
    "\n",
    "print(f\"Checkpoint: K_TRAIN={K_TRAIN}, N_CLASSES={N_CLASSES}, feat_dim_enhanced={EXP_IN}\")\n",
    "\n",
    "verifier_mlp = VerifierMLP(EXP_IN, N_CLASSES).to(device)\n",
    "verifier_mlp.load_state_dict(ckpt[\"mlp_enhanced\"], strict=True)\n",
    "verifier_mlp.eval()\n",
    "\n",
    "verifier_cnn = VerifierCNN(EXP_IN, N_CLASSES, feat_per_pos=10).to(device)\n",
    "verifier_cnn.load_state_dict(ckpt[\"cnn\"], strict=True)\n",
    "verifier_cnn.eval()\n",
    "\n",
    "verifier_transformer = VerifierTransformer(\n",
    "    EXP_IN, N_CLASSES, feat_per_pos=10, hidden_dim=128, n_heads=4, n_layers=2\n",
    ").to(device)\n",
    "verifier_transformer.load_state_dict(ckpt[\"transformer\"], strict=True)\n",
    "verifier_transformer.eval()\n",
    "\n",
    "cascade_verifier = CascadeVerifier(\n",
    "    verifiers=[verifier_mlp, verifier_cnn, verifier_transformer],\n",
    "    thresholds=[0.7, 0.8, 0.9]\n",
    ").to(device)\n",
    "\n",
    "print(\"Loaded verifiers and cascade\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def cascade_predict(cascade: CascadeVerifier, x: torch.Tensor, return_stage: bool = False):\n",
    "    last_logits = None\n",
    "    last_conf = None\n",
    "    last_stage = None\n",
    "\n",
    "    for i, (ver, th) in enumerate(zip(cascade.verifiers, cascade.thresholds)):\n",
    "        out = ver(x)\n",
    "        if isinstance(out, tuple):\n",
    "            logits, conf = out\n",
    "            conf_val = float(conf.view(-1)[0].item())\n",
    "        else:\n",
    "            logits = out\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            conf_val = float(probs.max(dim=-1).values.view(-1)[0].item())\n",
    "\n",
    "        last_logits = logits\n",
    "        last_conf = torch.tensor(conf_val, device=logits.device, dtype=logits.dtype)\n",
    "        last_stage = i\n",
    "\n",
    "        if conf_val >= th:\n",
    "            return (logits, last_conf, i) if return_stage else logits\n",
    "\n",
    "    return (last_logits, last_conf, last_stage) if return_stage else last_logits\n",
    "\n",
    "@torch.no_grad()\n",
    "def pack_features_for_verifier_enhanced(d_logits_list, d_tokens, committed_ids):\n",
    "    \"\"\"Pack enhanced features (10 per position) and pad/truncate to EXP_IN.\"\"\"\n",
    "    with monitor.timer(\"pack_features\"):\n",
    "        f = extract_features_gpu_enhanced(d_logits_list, d_tokens, committed_ids)  \n",
    "        if f.numel() < EXP_IN:\n",
    "            pad = torch.zeros(EXP_IN - f.numel(), device=f.device, dtype=f.dtype)\n",
    "            f = torch.cat([f, pad], dim=0)\n",
    "        elif f.numel() > EXP_IN:\n",
    "            f = f[:EXP_IN]\n",
    "        usable_k = min(len(d_tokens), K_TRAIN)\n",
    "        return f.unsqueeze(0).to(device), usable_k\n",
    "\n",
    "def pick_L_hat_from_logits(logits, tau=0.72, cap=None):\n",
    "    probs = torch.softmax(logits, dim=-1)[0]\n",
    "    tail = torch.flip(torch.cumsum(torch.flip(probs, dims=[0]), dim=0), dims=[0])\n",
    "    elig = (tail >= tau).nonzero(as_tuple=False).flatten()\n",
    "    L_hat = int(elig[-1].item()) if len(elig) else 0\n",
    "    if cap is not None:\n",
    "        L_hat = min(L_hat, cap)\n",
    "    return L_hat\n",
    "\n",
    "class AdaptiveController:\n",
    "    def __init__(self, config: AdaptiveConfig):\n",
    "        self.config = config\n",
    "        self.history = deque(maxlen=config.confidence_window)\n",
    "        self.k = config.k_init\n",
    "        self.tau = config.tau_init\n",
    "        self.margin = config.margin_init\n",
    "        self.weak_counter = 0\n",
    "\n",
    "    def update(self, accepted: int, asked: int, confidence: float = 0.5):\n",
    "        self.history.append(accepted)\n",
    "\n",
    "        if accepted >= 0.8 * asked:\n",
    "            self.k = min(self.k + 2, self.config.k_max)\n",
    "            self.weak_counter = 0\n",
    "        elif accepted < 0.3 * asked:\n",
    "            self.k = max(self.config.k_min, self.k // 2)\n",
    "            self.weak_counter += 1\n",
    "\n",
    "        if asked >= 4 and accepted == asked:\n",
    "            self.tau = max(self.config.tau_min, self.tau - self.config.adaptation_rate)\n",
    "            self.margin = max(self.config.margin_min, self.margin - self.config.adaptation_rate)\n",
    "        elif accepted < asked * 0.5:\n",
    "            self.tau = min(self.config.tau_max, self.tau + 2 * self.config.adaptation_rate)\n",
    "            self.margin = min(self.config.margin_max, self.margin + 2 * self.config.adaptation_rate)\n",
    "\n",
    "        if self.weak_counter >= self.config.weak_threshold:\n",
    "            self.tau = min(self.config.tau_max, self.tau + 0.05)\n",
    "            self.margin = min(self.config.margin_max, self.margin + 0.05)\n",
    "            self.weak_counter = 0\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.k, self.tau, self.margin\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_enhanced_vspec(prompt: str,\n",
    "                       max_new: int = 256,\n",
    "                       use_tree: bool = True,\n",
    "                       use_cascade: bool = True,\n",
    "                       verbose: bool = False):\n",
    "    tok = target.tok\n",
    "    t_inp = tok(prompt, return_tensors=\"pt\").to(target.device)[\"input_ids\"]\n",
    "    d_inp = tok(prompt, return_tensors=\"pt\").to(drafter.device)[\"input_ids\"]\n",
    "\n",
    "    t_state = init_state(target, t_inp)\n",
    "    d_state = init_state(drafter, d_inp)\n",
    "\n",
    "    committed_ids = t_inp.clone()\n",
    "    committed_len = 0\n",
    "\n",
    "    controller = AdaptiveController(CONFIG)\n",
    "\n",
    "    stats = {\n",
    "        'target_calls': 0, 'drafter_calls': 0, 'blocks': 0,\n",
    "        'total_accepted': 0, 'total_asked': 0, 'tree_explores': 0,\n",
    "        'cascade_stages': [], 'time_breakdown': defaultdict(float)\n",
    "    }\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    while committed_len < max_new:\n",
    "        k, tau, margin = controller.get_params()\n",
    "\n",
    "        # Draft\n",
    "        with monitor.timer(\"draft_phase\"):\n",
    "            if use_tree and k >= 6:\n",
    "                d_tokens, d_logits_list, d_state_new, tree_score = drafter_draft_tree(\n",
    "                    drafter, d_state, k, branching_factor=2, temperature=0.0\n",
    "                )\n",
    "                stats['tree_explores'] += 1\n",
    "            else:\n",
    "                d_tokens, d_logits_list, d_state_new = drafter_draft_chunk_cached(\n",
    "                    drafter, d_state, k\n",
    "                )\n",
    "                tree_score = 1.0\n",
    "        stats['drafter_calls'] += 1\n",
    "\n",
    "        with monitor.timer(\"feature_predict\"):\n",
    "            feats, usable_k = pack_features_for_verifier_enhanced(d_logits_list, d_tokens, committed_ids)\n",
    "\n",
    "            if use_cascade:\n",
    "                logits, conf, stage = cascade_predict(cascade_verifier, feats, return_stage=True)\n",
    "                stats['cascade_stages'].append(stage)\n",
    "            else:\n",
    "                out = verifier_mlp(feats)\n",
    "                if isinstance(out, tuple):\n",
    "                    logits, conf = out\n",
    "                    conf = conf.view(-1)[0]\n",
    "                else:\n",
    "                    logits = out\n",
    "                    conf = torch.softmax(logits, dim=-1).max(dim=-1).values.view(-1)[0]\n",
    "\n",
    "            L_model = pick_L_hat_from_logits(logits, tau=tau, cap=usable_k)\n",
    "            L_heur  = heuristic_L_hat_gpu(d_logits_list, d_tokens, committed_ids,\n",
    "                                          margin_thresh=margin, min_keep=2, max_k=len(d_tokens))\n",
    "            L_hat = max(L_model, L_heur) if float(conf) < 0.6 else L_model\n",
    "            L_hat = min(L_hat, len(d_tokens))\n",
    "\n",
    "        stats['total_asked'] += L_hat\n",
    "\n",
    "        if L_hat < max(2, int(0.3 * k)):\n",
    "            with monitor.timer(\"single_token\"):\n",
    "                nxt_ids, t_state = greedy_step_with_cache(target, t_state, None)\n",
    "                _, d_state = greedy_step_with_cache(drafter, d_state, nxt_ids)\n",
    "                committed_ids = torch.cat([committed_ids, nxt_ids.to(committed_ids.device)], 1)\n",
    "                committed_len += 1\n",
    "                stats['target_calls'] += 1\n",
    "                controller.update(0, L_hat, float(conf))\n",
    "            continue\n",
    "\n",
    "        with monitor.timer(\"verify_phase\"):\n",
    "            ok, accepted, t_state_new = target_verify_block_once(target, t_state, d_tokens, L_hat)\n",
    "            stats['target_calls'] += 1 + (0 if ok or accepted == 0 else 1)\n",
    "            stats['blocks'] += 1\n",
    "\n",
    "        stats['total_accepted'] += accepted\n",
    "\n",
    "        if accepted > 0:\n",
    "            commit_tokens = d_tokens[:accepted]\n",
    "            committed_ids = torch.cat(\n",
    "                [committed_ids, torch.tensor([commit_tokens], device=committed_ids.device)], 1\n",
    "            )\n",
    "            committed_len += accepted\n",
    "            t_state = t_state_new\n",
    "\n",
    "            d_state_tmp = d_state\n",
    "            for tok_id in commit_tokens:\n",
    "                _, d_state_tmp = greedy_step_with_cache(drafter, d_state_tmp, tok_id)\n",
    "            d_state = d_state_tmp\n",
    "\n",
    "            if accepted == L_hat and accepted < len(d_tokens) and accepted < k - 2:\n",
    "                with monitor.timer(\"topup\"):\n",
    "                    tail = d_tokens[accepted:min(len(d_tokens), accepted + 2)]\n",
    "                    ok2, acc2, t_state2 = target_verify_block_once(target, t_state, tail, len(tail))\n",
    "                    stats['target_calls'] += 1 + (0 if ok2 or acc2 == 0 else 1)\n",
    "                    if acc2 > 0:\n",
    "                        committed_ids = torch.cat(\n",
    "                            [committed_ids, torch.tensor([tail[:acc2]], device=committed_ids.device)], 1\n",
    "                        )\n",
    "                        committed_len += acc2\n",
    "                        t_state = t_state2\n",
    "                        for tok_id in tail[:acc2]:\n",
    "                            _, d_state = greedy_step_with_cache(drafter, d_state, tok_id)\n",
    "                        stats['total_accepted'] += acc2\n",
    "\n",
    "        elif accepted == 0 and L_hat > 4:\n",
    "            with monitor.timer(\"backoff\"):\n",
    "                L_backoff = max(2, L_hat // 2)\n",
    "                ok_b, acc_b, t_state_b = target_verify_block_once(target, t_state, d_tokens, L_backoff)\n",
    "                stats['target_calls'] += 1 + (0 if ok_b or acc_b == 0 else 1)\n",
    "                if acc_b > 0:\n",
    "                    commit_tokens = d_tokens[:acc_b]\n",
    "                    committed_ids = torch.cat(\n",
    "                        [committed_ids, torch.tensor([commit_tokens], device=committed_ids.device)], 1\n",
    "                    )\n",
    "                    committed_len += acc_b\n",
    "                    t_state = t_state_b\n",
    "                    d_state_tmp = d_state\n",
    "                    for tok_id in commit_tokens:\n",
    "                        _, d_state_tmp = greedy_step_with_cache(drafter, d_state_tmp, tok_id)\n",
    "                    d_state = d_state_tmp\n",
    "                    stats['total_accepted'] += acc_b\n",
    "\n",
    "        if accepted == 0:\n",
    "            with monitor.timer(\"fallback\"):\n",
    "                nxt_ids, t_state = greedy_step_with_cache(target, t_state, None)\n",
    "                _, d_state = greedy_step_with_cache(drafter, d_state, nxt_ids)\n",
    "                committed_ids = torch.cat([committed_ids, nxt_ids.to(committed_ids.device)], 1)\n",
    "                committed_len += 1\n",
    "                stats['target_calls'] += 1\n",
    "\n",
    "        controller.update(accepted, L_hat, float(conf))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    elapsed = time.perf_counter() - t0\n",
    "\n",
    "    if monitor.enabled:\n",
    "        stats[\"time_breakdown\"] = monitor.report()\n",
    "\n",
    "    stats[\"tokens_per_sec\"] = committed_len / max(elapsed, 1e-6)\n",
    "    stats[\"mean_accept\"] = stats[\"total_accepted\"] / max(1, stats[\"blocks\"])\n",
    "    stats[\"accept_rate\"] = stats[\"total_accepted\"] / max(1, stats[\"total_asked\"])\n",
    "    stats[\"time\"] = elapsed\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== Enhanced V-Spec Results ===\")\n",
    "        print(f\"Tokens/sec: {stats['tokens_per_sec']:.2f}\")\n",
    "        print(f\"Mean accept: {stats['mean_accept']:.2f}\")\n",
    "        print(f\"Accept rate: {stats['accept_rate']:.2%}\")\n",
    "        print(f\"Target calls: {stats['target_calls']}\")\n",
    "        print(f\"Drafter calls: {stats['drafter_calls']}\")\n",
    "        print(f\"Tree explores: {stats['tree_explores']}\")\n",
    "        if stats['cascade_stages']:\n",
    "            print(f\"Avg cascade stage: {np.mean(stats['cascade_stages']):.2f}\")\n",
    "        print(\"\\nTiming breakdown:\")\n",
    "        for name, info in stats[\"time_breakdown\"].items():\n",
    "            print(f\"  {name}: {info['mean_ms']:.2f}ms avg ({info['count']} calls)\")\n",
    "\n",
    "    monitor.timings.clear()\n",
    "    monitor.counts.clear()\n",
    "\n",
    "    return tok.decode(committed_ids[0].tolist()), stats\n",
    "\n",
    "print(\" Enhanced runtime loaded\")\n",
    "print(\"  Features: Tree speculation, cascade verification, adaptive control\")\n",
    "print(\"  Ready to run with run_enhanced_vspec()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4a599-77d0-4a4c-aeb9-23dd20af78d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive benchmark...\n",
      "Running benchmark on 12 prompts...\n",
      "============================================================\n",
      "\n",
      "[1/12] Testing prompt: Calculate 47 * 83 step by step....\n",
      "  Running greedy... 41.3 tok/s\n",
      "  Running spec(k=8)... 8.0 tok/s\n",
      "  Running enhanced (full)... 20.4 tok/s\n",
      "  Running enhanced (no tree)... 21.1 tok/s\n",
      "  Running enhanced (no cascade)... 23.3 tok/s\n",
      "\n",
      "[2/12] Testing prompt: If a train travels 120 km at 60 km/h and then 180 ...\n",
      "  Running greedy... 49.9 tok/s\n",
      "  Running spec(k=8)... 8.8 tok/s\n",
      "  Running enhanced (full)... 19.3 tok/s\n",
      "  Running enhanced (no tree)... 19.6 tok/s\n",
      "  Running enhanced (no cascade)... 19.3 tok/s\n",
      "\n",
      "[3/12] Testing prompt: Solve for x: 3x + 7 = 22. Show your work....\n",
      "  Running greedy... 49.7 tok/s\n",
      "  Running spec(k=8)... 8.9 tok/s\n",
      "  Running enhanced (full)... 17.6 tok/s\n",
      "  Running enhanced (no tree)... 17.4 tok/s\n",
      "  Running enhanced (no cascade)... 18.4 tok/s\n",
      "\n",
      "[4/12] Testing prompt: Write a Python function to find the nth Fibonacci ...\n",
      "  Running greedy... 49.5 tok/s\n",
      "  Running spec(k=8)... 7.8 tok/s\n",
      "  Running enhanced (full)... 22.4 tok/s\n",
      "  Running enhanced (no tree)... 21.2 tok/s\n",
      "  Running enhanced (no cascade)... 23.1 tok/s\n",
      "\n",
      "[5/12] Testing prompt: Implement a binary search tree in Python with inse...\n",
      "  Running greedy... 47.1 tok/s\n",
      "  Running spec(k=8)... 7.1 tok/s\n",
      "  Running enhanced (full)... 18.1 tok/s\n",
      "  Running enhanced (no tree)... 18.3 tok/s\n",
      "  Running enhanced (no cascade)... 23.8 tok/s\n",
      "\n",
      "[6/12] Testing prompt: Create a function to validate if a string has bala...\n",
      "  Running greedy... 46.3 tok/s\n",
      "  Running spec(k=8)... 6.9 tok/s\n",
      "  Running enhanced (full)... 17.3 tok/s\n",
      "  Running enhanced (no tree)... 17.2 tok/s\n",
      "  Running enhanced (no cascade)... 20.3 tok/s\n",
      "\n",
      "[7/12] Testing prompt: Explain how transformers work in machine learning ...\n",
      "  Running greedy... 47.1 tok/s\n",
      "  Running spec(k=8)... 7.0 tok/s\n",
      "  Running enhanced (full)... 16.6 tok/s\n",
      "  Running enhanced (no tree)... 16.7 tok/s\n",
      "  Running enhanced (no cascade)... 15.9 tok/s\n",
      "\n",
      "[8/12] Testing prompt: What are the main causes of climate change? Provid...\n",
      "  Running greedy... 46.7 tok/s\n",
      "  Running spec(k=8)... 7.1 tok/s\n",
      "  Running enhanced (full)... 16.0 tok/s\n",
      "  Running enhanced (no tree)... 15.7 tok/s\n",
      "  Running enhanced (no cascade)... 16.9 tok/s\n",
      "\n",
      "[9/12] Testing prompt: Describe the process of photosynthesis in simple t...\n",
      "  Running greedy... 49.6 tok/s\n",
      "  Running spec(k=8)... 7.8 tok/s\n",
      "  Running enhanced (full)... 22.7 tok/s\n",
      "  Running enhanced (no tree)... 18.2 tok/s\n",
      "  Running enhanced (no cascade)... 16.7 tok/s\n",
      "\n",
      "[10/12] Testing prompt: Write a short story about a robot learning to pain...\n",
      "  Running greedy... 50.3 tok/s\n",
      "  Running spec(k=8)... 7.2 tok/s\n",
      "  Running enhanced (full)... 26.8 tok/s\n",
      "  Running enhanced (no tree)... 26.7 tok/s\n",
      "  Running enhanced (no cascade)... 24.4 tok/s\n",
      "\n",
      "[11/12] Testing prompt: Describe a futuristic city in the year 2150....\n",
      "  Running greedy... 49.4 tok/s\n",
      "  Running spec(k=8)... 7.6 tok/s\n",
      "  Running enhanced (full)... 21.0 tok/s\n",
      "  Running enhanced (no tree)... 21.3 tok/s\n",
      "  Running enhanced (no cascade)... 26.9 tok/s\n",
      "\n",
      "[12/12] Testing prompt: Calculate 47 * 83 step by step....\n",
      "  Running greedy... 50.1 tok/s\n",
      "  Running spec(k=8)... 8.2 tok/s\n",
      "  Running enhanced (full)... 21.1 tok/s\n",
      "  Running enhanced (no tree)... 20.9 tok/s\n",
      "  Running enhanced (no cascade)... 23.4 tok/s\n",
      "\n",
      "============================================================\n",
      "BENCHMARK RESULTS\n",
      "============================================================\n",
      "             method  mean_tps  std_tps  median_tps  mean_accept  target_calls  drafter_calls  speedup\n",
      "             greedy 48.059796 2.490920   49.444686     1.000000    256.000000       0.000000 1.000000\n",
      "            spec_k8  7.704556 0.667392    7.681430     0.454769   1905.000000     211.666667 0.160312\n",
      "      enhanced_full 19.946101 2.974991   19.868920     4.056529    113.833333      65.166667 0.415027\n",
      "   enhanced_no_tree 19.517016 2.859572   18.939784     4.056529    113.833333      65.166667 0.406099\n",
      "enhanced_no_cascade 21.033880 3.408509   21.692388     4.569542    105.250000      61.166667 0.437661\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Benchmark complete! Results saved to ./benchmark_results.png\n",
      "✓ Detailed analysis saved to benchmark_analysis.csv\n",
      "\n",
      "============================================================\n",
      "EXECUTIVE SUMMARY\n",
      "============================================================\n",
      "Best performing method: greedy\n",
      "Maximum speedup achieved: 1.00x over greedy\n",
      "Average acceptance rate: 3.28 tokens/block\n",
      "\n",
      "============================================================\n",
      "DETAILED COMPARISON\n",
      "============================================================\n",
      "Standard Spec (k=8): 0.16x speedup\n",
      "Enhanced V-Spec: 0.42x speedup\n",
      "Improvement: 158.9% better than standard spec\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "\n",
    "def get_test_prompts(n=20):\n",
    "   prompts = []\n",
    "   \n",
    "   # Math problems\n",
    "   prompts.extend([\n",
    "       \"Calculate 47 * 83 step by step.\",\n",
    "       \"If a train travels 120 km at 60 km/h and then 180 km at 90 km/h, what's the average speed?\",\n",
    "       \"Solve for x: 3x + 7 = 22. Show your work.\",\n",
    "   ])\n",
    "   \n",
    "   # Code tasks\n",
    "   prompts.extend([\n",
    "       \"Write a Python function to find the nth Fibonacci number using dynamic programming.\",\n",
    "       \"Implement a binary search tree in Python with insert and search methods.\",\n",
    "       \"Create a function to validate if a string has balanced parentheses.\",\n",
    "   ])\n",
    "   \n",
    "   # Reasoning\n",
    "   prompts.extend([\n",
    "       \"Explain how transformers work in machine learning to a beginner.\",\n",
    "       \"What are the main causes of climate change? Provide a concise explanation.\",\n",
    "       \"Describe the process of photosynthesis in simple terms.\",\n",
    "   ])\n",
    "   \n",
    "   # Story/Creative\n",
    "   prompts.extend([\n",
    "       \"Write a short story about a robot learning to paint.\",\n",
    "       \"Describe a futuristic city in the year 2150.\",\n",
    "   ])\n",
    "   \n",
    "   # Extend to n prompts by cycling\n",
    "   while len(prompts) < n:\n",
    "       prompts.extend(prompts[:min(n - len(prompts), len(prompts))])\n",
    "   \n",
    "   return prompts[:n]\n",
    "\n",
    "def run_benchmark(n_prompts=16, max_new=256):\n",
    "   prompts = get_test_prompts(n_prompts)\n",
    "   results = {\n",
    "       'greedy': [],\n",
    "       'spec_k8': [],\n",
    "       'enhanced_full': [],\n",
    "       'enhanced_no_tree': [],\n",
    "       'enhanced_no_cascade': []\n",
    "   }\n",
    "   \n",
    "   print(f\"Running benchmark on {n_prompts} prompts...\")\n",
    "   print(\"=\" * 60)\n",
    "   \n",
    "   for i, prompt in enumerate(prompts):\n",
    "       print(f\"\\n[{i+1}/{n_prompts}] Testing prompt: {prompt[:50]}...\")\n",
    "       \n",
    "       # 1. Greedy baseline\n",
    "       print(\"  Running greedy...\", end=\"\")\n",
    "       greedy_res = run_greedy_cached(prompt, max_new=max_new)\n",
    "       results['greedy'].append(greedy_res)\n",
    "       print(f\" {greedy_res['tokens_per_s']:.1f} tok/s\")\n",
    "       \n",
    "       # 2. Standard spec (k=8)\n",
    "       print(\"  Running spec(k=8)...\", end=\"\")\n",
    "       spec_res = run_spec_block(prompt, k=8, max_new=max_new)\n",
    "       results['spec_k8'].append(spec_res)\n",
    "       print(f\" {spec_res['tokens_per_s']:.1f} tok/s\")\n",
    "       \n",
    "       # 3. Enhanced with all features\n",
    "       print(\"  Running enhanced (full)...\", end=\"\")\n",
    "       _, enhanced_res = run_enhanced_vspec(\n",
    "           prompt, max_new=max_new, \n",
    "           use_tree=True, use_cascade=True, verbose=False\n",
    "       )\n",
    "       results['enhanced_full'].append(enhanced_res)\n",
    "       print(f\" {enhanced_res['tokens_per_sec']:.1f} tok/s\")\n",
    "       \n",
    "       # 4. Enhanced without tree\n",
    "       print(\"  Running enhanced (no tree)...\", end=\"\")\n",
    "       _, enhanced_no_tree = run_enhanced_vspec(\n",
    "           prompt, max_new=max_new,\n",
    "           use_tree=False, use_cascade=True, verbose=False\n",
    "       )\n",
    "       results['enhanced_no_tree'].append(enhanced_no_tree)\n",
    "       print(f\" {enhanced_no_tree['tokens_per_sec']:.1f} tok/s\")\n",
    "       \n",
    "       # 5. Enhanced without cascade\n",
    "       print(\"  Running enhanced (no cascade)...\", end=\"\")\n",
    "       _, enhanced_no_cascade = run_enhanced_vspec(\n",
    "           prompt, max_new=max_new,\n",
    "           use_tree=True, use_cascade=False, verbose=False\n",
    "       )\n",
    "       results['enhanced_no_cascade'].append(enhanced_no_cascade)\n",
    "       print(f\" {enhanced_no_cascade['tokens_per_sec']:.1f} tok/s\")\n",
    "   \n",
    "   return results, prompts\n",
    "\n",
    "print(\"Starting comprehensive benchmark...\")\n",
    "results, prompts = run_benchmark(n_prompts=12, max_new=256)\n",
    "\n",
    "def analyze_results(results: Dict[str, List]):\n",
    "   rows = []\n",
    "   \n",
    "   for method, res_list in results.items():\n",
    "       if not res_list:\n",
    "           continue\n",
    "       \n",
    "       if method == 'greedy':\n",
    "           tps = [r['tokens_per_s'] for r in res_list]\n",
    "           rows.append({\n",
    "               'method': method,\n",
    "               'mean_tps': np.mean(tps),\n",
    "               'std_tps': np.std(tps),\n",
    "               'median_tps': np.median(tps),\n",
    "               'mean_accept': 1.0,\n",
    "               'target_calls': np.mean([r['tgt_calls'] for r in res_list]),\n",
    "               'drafter_calls': 0\n",
    "           })\n",
    "       else:\n",
    "           tps_key = 'tokens_per_sec' if 'tokens_per_sec' in res_list[0] else 'tokens_per_s'\n",
    "           tps = [r[tps_key] for r in res_list]\n",
    "           \n",
    "           accept_key = 'mean_accept' if 'mean_accept' in res_list[0] else 0\n",
    "           mean_accept = np.mean([r.get(accept_key, 0) for r in res_list]) if accept_key else 0\n",
    "           \n",
    "           rows.append({\n",
    "               'method': method,\n",
    "               'mean_tps': np.mean(tps),\n",
    "               'std_tps': np.std(tps),\n",
    "               'median_tps': np.median(tps),\n",
    "               'mean_accept': mean_accept,\n",
    "               'target_calls': np.mean([r.get('tgt_calls', r.get('target_calls', 0)) for r in res_list]),\n",
    "               'drafter_calls': np.mean([r.get('drafter_calls', r.get('d_calls', 0)) for r in res_list])\n",
    "           })\n",
    "   \n",
    "   df = pd.DataFrame(rows)\n",
    "   \n",
    "   greedy_tps = df[df['method'] == 'greedy']['mean_tps'].values[0]\n",
    "   df['speedup'] = df['mean_tps'] / greedy_tps\n",
    "   \n",
    "   return df\n",
    "\n",
    "analysis = analyze_results(results)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BENCHMARK RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(analysis.to_string(index=False))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# 1. Throughput comparison\n",
    "ax = axes[0, 0]\n",
    "methods = analysis['method'].values\n",
    "throughputs = analysis['mean_tps'].values\n",
    "colors = ['gray', 'blue', 'green', 'orange', 'red']\n",
    "bars = ax.bar(methods, throughputs, color=colors[:len(methods)])\n",
    "ax.set_ylabel('Tokens/sec')\n",
    "ax.set_title('Throughput Comparison')\n",
    "ax.set_xticklabels(methods, rotation=45, ha='right')\n",
    "for bar, val in zip(bars, throughputs):\n",
    "   ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "           f'{val:.1f}', ha='center', va='bottom')\n",
    "\n",
    "# 2. Speedup over greedy\n",
    "ax = axes[0, 1]\n",
    "speedups = analysis['speedup'].values\n",
    "bars = ax.bar(methods, speedups, color=colors[:len(methods)])\n",
    "ax.set_ylabel('Speedup vs Greedy')\n",
    "ax.set_title('Relative Performance')\n",
    "ax.axhline(y=1.0, color='black', linestyle='--', alpha=0.3)\n",
    "ax.set_xticklabels(methods, rotation=45, ha='right')\n",
    "\n",
    "for bar, val in zip(bars, speedups):\n",
    "   ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(),\n",
    "           f'{val:.2f}x', ha='center', va='bottom')\n",
    "\n",
    "# 3. Acceptance rates\n",
    "ax = axes[0, 2]\n",
    "accept_rates = analysis['mean_accept'].values\n",
    "bars = ax.bar(methods[1:], accept_rates[1:], color=colors[1:len(methods)])\n",
    "ax.set_ylabel('Mean Accepted Tokens')\n",
    "ax.set_title('Draft Acceptance Rate')\n",
    "ax.set_xticklabels(methods[1:], rotation=45, ha='right')\n",
    "\n",
    "# 4. Model calls comparison\n",
    "ax = axes[1, 0]\n",
    "target_calls = analysis['target_calls'].values\n",
    "drafter_calls = analysis['drafter_calls'].values\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, target_calls, width, label='Target', color='darkblue')\n",
    "ax.bar(x + width/2, drafter_calls, width, label='Drafter', color='lightblue')\n",
    "ax.set_ylabel('Calls per sequence')\n",
    "ax.set_title('Model Call Efficiency')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(methods, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# 5. Variance analysis\n",
    "ax = axes[1, 1]\n",
    "std_tps = analysis['std_tps'].values\n",
    "ax.bar(methods, std_tps, color=colors[:len(methods)])\n",
    "ax.set_ylabel('Std Dev (tokens/sec)')\n",
    "ax.set_title('Performance Stability')\n",
    "ax.set_xticklabels(methods, rotation=45, ha='right')\n",
    "\n",
    "# 6. Feature ablation impact\n",
    "ax = axes[1, 2]\n",
    "if 'enhanced_full' in analysis['method'].values:\n",
    "   base_idx = analysis[analysis['method'] == 'enhanced_full'].index[0]\n",
    "   base_tps = analysis.loc[base_idx, 'mean_tps']\n",
    "   \n",
    "   ablation_data = []\n",
    "   if 'enhanced_no_tree' in analysis['method'].values:\n",
    "       no_tree_idx = analysis[analysis['method'] == 'enhanced_no_tree'].index[0]\n",
    "       ablation_data.append(('Tree', base_tps - analysis.loc[no_tree_idx, 'mean_tps']))\n",
    "   \n",
    "   if 'enhanced_no_cascade' in analysis['method'].values:\n",
    "       no_cascade_idx = analysis[analysis['method'] == 'enhanced_no_cascade'].index[0]\n",
    "       ablation_data.append(('Cascade', base_tps - analysis.loc[no_cascade_idx, 'mean_tps']))\n",
    "   \n",
    "   if ablation_data:\n",
    "       features, impacts = zip(*ablation_data)\n",
    "       ax.bar(features, impacts, color=['purple', 'brown'])\n",
    "       ax.set_ylabel('Performance Impact (tok/s)')\n",
    "       ax.set_title('Feature Contribution')\n",
    "       ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{os.environ.get('BASE_DIR', '.')}/benchmark_results.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBenchmark complete! Results saved to {os.environ.get('BASE_DIR', '.')}/benchmark_results.png\")\n",
    "\n",
    "analysis.to_csv(f\"{os.environ.get('BASE_DIR', '.')}/benchmark_analysis.csv\", index=False)\n",
    "print(f\"Detailed analysis saved to benchmark_analysis.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "best_method = analysis.loc[analysis['speedup'].idxmax(), 'method']\n",
    "best_speedup = analysis.loc[analysis['speedup'].idxmax(), 'speedup']\n",
    "print(f\"Best performing method: {best_method}\")\n",
    "print(f\"Maximum speedup achieved: {best_speedup:.2f}x over greedy\")\n",
    "print(f\"Average acceptance rate: {analysis[analysis['method'] != 'greedy']['mean_accept'].mean():.2f} tokens/block\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DETAILED COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "if 'enhanced_full' in analysis['method'].values:\n",
    "   enhanced_idx = analysis[analysis['method'] == 'enhanced_full'].index[0]\n",
    "   spec_idx = analysis[analysis['method'] == 'spec_k8'].index[0]\n",
    "   \n",
    "   enhanced_speedup = analysis.loc[enhanced_idx, 'speedup']\n",
    "   spec_speedup = analysis.loc[spec_idx, 'speedup']\n",
    "   improvement = ((enhanced_speedup - spec_speedup) / spec_speedup) * 100\n",
    "   \n",
    "   print(f\"Standard Spec (k=8): {spec_speedup:.2f}x speedup\")\n",
    "   print(f\"Enhanced V-Spec: {enhanced_speedup:.2f}x speedup\")\n",
    "   print(f\"Improvement: {improvement:.1f}% better than standard spec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c537bdd-8607-4a0d-8400-58c467a66021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INTERACTIVE DEMO FUNCTIONS\n",
      "============================================================\n",
      "\n",
      "1. quick_test(prompt, max_tokens)\n",
      "   - Compare all methods on a single prompt\n",
      "   - Example: quick_test('Explain quantum computing', 256)\n",
      "\n",
      "2. profile_performance(prompt, max_tokens)\n",
      "   - Detailed performance profiling\n",
      "   - Shows where time is spent\n",
      "\n",
      "3. compare_on_prompt_types()\n",
      "   - Test on different prompt categories\n",
      "   - Math, code, reasoning, creative, factual\n",
      "\n",
      "4. test_adaptive_behavior(prompt, iterations)\n",
      "   - Test consistency across multiple runs\n",
      "\n",
      "============================================================\n",
      "\n",
      "Running quick demo...\n",
      "\n",
      "============================================================\n",
      "PROMPT: What are the benefits of renewable energy?\n",
      "============================================================\n",
      "\n",
      "1. GREEDY BASELINE\n",
      "--------------------\n",
      "Speed: 44.76 tokens/sec\n",
      "Time: 2.89s\n",
      "Target calls: 128\n",
      "\n",
      "2. STANDARD SPECULATIVE (k=8)\n",
      "--------------------\n",
      "Speed: 4.20 tokens/sec\n",
      "Speedup: 0.09x\n",
      "Mean accept: 0.49\n",
      "Target calls: 927\n",
      "\n",
      "3. ENHANCED V-SPEC (Full)\n",
      "--------------------\n",
      "Speed: 11.22 tokens/sec\n",
      "Speedup: 0.25x\n",
      "Mean accept: 3.53\n",
      "Accept rate: 55.46%\n",
      "Target calls: 64\n",
      "\n",
      "============================================================\n",
      "IMPROVEMENTS\n",
      "============================================================\n",
      "Enhanced vs Standard Spec: +167.1%\n",
      "Enhanced vs Greedy: -74.9%\n",
      "\n",
      "============================================================\n",
      "SAMPLE OUTPUT (first 200 chars):\n",
      "============================================================\n",
      "What are the benefits of renewable energy? Renewable energy sources of hydro not produce greenhouse gases, making them a more sustainable and environmentally.\n",
      "\n",
      "2. Reduced dependence on fossil fuels: R...\n",
      "\n",
      "============================================================\n",
      "PROMPT: What is transfer learning?\n",
      "============================================================\n",
      "\n",
      "1. GREEDY BASELINE\n",
      "--------------------\n",
      "Speed: 48.74 tokens/sec\n",
      "Time: 2.65s\n",
      "Target calls: 128\n",
      "\n",
      "2. STANDARD SPECULATIVE (k=8)\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 231\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRunning quick demo...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    229\u001b[39m demo_results = quick_test(\u001b[33m\"\u001b[39m\u001b[33mWhat are the benefits of renewable energy?\u001b[39m\u001b[33m\"\u001b[39m, max_tokens=\u001b[32m128\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m _ = \u001b[43mquick_test\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is transfer learning?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m _ = profile_performance(\u001b[33m\"\u001b[39m\u001b[33mImplement a binary search in Python.\u001b[39m\u001b[33m\"\u001b[39m, max_tokens=\u001b[32m128\u001b[39m)\n\u001b[32m    233\u001b[39m by_type = compare_on_prompt_types()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mquick_test\u001b[39m\u001b[34m(prompt, max_tokens)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m2. STANDARD SPECULATIVE (k=8)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m20\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m spec_res = \u001b[43mrun_spec_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33mspec\u001b[39m\u001b[33m'\u001b[39m] = spec_res\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSpeed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec_res[\u001b[33m'\u001b[39m\u001b[33mtokens_per_s\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tokens/sec\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 357\u001b[39m, in \u001b[36mrun_spec_block\u001b[39m\u001b[34m(prompt, k, max_new)\u001b[39m\n\u001b[32m    355\u001b[39m t0 = time.perf_counter()\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m committed < max_new:\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     d_tokens, d_logits_list, _ = \u001b[43mdrafter_draft_chunk_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrafter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m     d_calls += \u001b[32m1\u001b[39m\n\u001b[32m    360\u001b[39m     L, t_new = target_verify_and_update(target, t_state, d_tokens)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 247\u001b[39m, in \u001b[36mdrafter_draft_chunk_cached\u001b[39m\u001b[34m(drafter_bundle, d_state, k)\u001b[39m\n\u001b[32m    245\u001b[39m     next_id = \u001b[38;5;28mint\u001b[39m(state.last_logits.argmax(-\u001b[32m1\u001b[39m).item())\n\u001b[32m    246\u001b[39m     per_step_logits.append(state.last_logits)\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     _, state = \u001b[43mgreedy_step_with_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrafter_bundle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m     tokens.append(next_id)\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokens, per_step_logits, state\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 231\u001b[39m, in \u001b[36mgreedy_step_with_cache\u001b[39m\u001b[34m(bundle, state, next_token)\u001b[39m\n\u001b[32m    228\u001b[39m inp = torch.tensor([[chosen_id]], device=dev, dtype=torch.long)\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m monitor.timer(\u001b[33m\"\u001b[39m\u001b[33mmodel_forward_step\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     out = \u001b[43mbundle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inp, KVState(\n\u001b[32m    234\u001b[39m     past=\u001b[38;5;28mgetattr\u001b[39m(out, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    235\u001b[39m     last_logits=out.logits[:, -\u001b[32m1\u001b[39m, :],\n\u001b[32m    236\u001b[39m     seq_len=state.seq_len + \u001b[32m1\u001b[39m\n\u001b[32m    237\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:959\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    957\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    958\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m959\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    961\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py:450\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    431\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    432\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    433\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    435\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    448\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    449\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:1083\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1080\u001b[39m                 module.forward = make_capture_wrapper(module, original_forward, key, specs.index)\n\u001b[32m   1081\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[32m   1085\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py:379\u001b[39m, in \u001b[36mQwen2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    376\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    392\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    393\u001b[39m     past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    394\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py:246\u001b[39m, in \u001b[36mQwen2DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    244\u001b[39m residual = hidden_states\n\u001b[32m    245\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py:45\u001b[39m, in \u001b[36mQwen2MLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     down_proj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdown_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py:561\u001b[39m, in \u001b[36mLinear4bit.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    559\u001b[39m     x = x.to(\u001b[38;5;28mself\u001b[39m.compute_dtype)\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m bias = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias.to(\u001b[38;5;28mself\u001b[39m.compute_dtype)\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# IPEX CPU will change weight to 4D so don't need transpose\u001b[39;00m\n\u001b[32m    563\u001b[39m weight = \u001b[38;5;28mself\u001b[39m.weight.t() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.weight.dim() == \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.weight\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1927\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1922\u001b[39m         \u001b[38;5;28mself\u001b[39m._backward_pre_hooks = OrderedDict()\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[32m   1926\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1927\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Union[Tensor, \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1928\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m   1929\u001b[39m         _parameters = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def quick_test(prompt=None, max_tokens=256):\n",
    "    if prompt is None:\n",
    "        prompt = \"Explain how neural networks learn in simple terms.\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROMPT: {prompt}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. Greedy\n",
    "    print(\"\\n1. GREEDY BASELINE\")\n",
    "    print(\"-\" * 20)\n",
    "    t0 = time.perf_counter()\n",
    "    greedy_res = run_greedy_cached(prompt, max_new=max_tokens)\n",
    "    greedy_time = time.perf_counter() - t0\n",
    "    results['greedy'] = greedy_res\n",
    "    print(f\"Speed: {greedy_res['tokens_per_s']:.2f} tokens/sec\")\n",
    "    print(f\"Time: {greedy_time:.2f}s\")\n",
    "    print(f\"Target calls: {greedy_res['tgt_calls']}\")\n",
    "    \n",
    "    # 2. Standard Spec\n",
    "    print(\"\\n2. STANDARD SPECULATIVE (k=8)\")\n",
    "    print(\"-\" * 20)\n",
    "    spec_res = run_spec_block(prompt, k=8, max_new=max_tokens)\n",
    "    results['spec'] = spec_res\n",
    "    print(f\"Speed: {spec_res['tokens_per_s']:.2f} tokens/sec\")\n",
    "    print(f\"Speedup: {spec_res['tokens_per_s']/greedy_res['tokens_per_s']:.2f}x\")\n",
    "    print(f\"Mean accept: {spec_res['mean_accept']:.2f}\")\n",
    "    print(f\"Target calls: {spec_res['tgt_calls']}\")\n",
    "    \n",
    "    # 3. Enhanced V-Spec\n",
    "    print(\"\\n3. ENHANCED V-SPEC (Full)\")\n",
    "    print(\"-\" * 20)\n",
    "    text, enhanced_res = run_enhanced_vspec(\n",
    "        prompt, max_new=max_tokens, \n",
    "        use_tree=True, use_cascade=True, verbose=False\n",
    "    )\n",
    "    results['enhanced'] = enhanced_res\n",
    "    print(f\"Speed: {enhanced_res['tokens_per_sec']:.2f} tokens/sec\")\n",
    "    print(f\"Speedup: {enhanced_res['tokens_per_sec']/greedy_res['tokens_per_s']:.2f}x\")\n",
    "    print(f\"Mean accept: {enhanced_res['mean_accept']:.2f}\")\n",
    "    print(f\"Accept rate: {enhanced_res['accept_rate']:.2%}\")\n",
    "    print(f\"Target calls: {enhanced_res['target_calls']}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"IMPROVEMENTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    spec_improvement = ((enhanced_res['tokens_per_sec'] - spec_res['tokens_per_s']) / spec_res['tokens_per_s']) * 100\n",
    "    print(f\"Enhanced vs Standard Spec: {spec_improvement:+.1f}%\")\n",
    "    \n",
    "    greedy_improvement = ((enhanced_res['tokens_per_sec'] - greedy_res['tokens_per_s']) / greedy_res['tokens_per_s']) * 100\n",
    "    print(f\"Enhanced vs Greedy: {greedy_improvement:+.1f}%\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SAMPLE OUTPUT (first 200 chars):\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(text[:200] + \"...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def profile_performance(prompt=\"Write a Python function to sort a list.\", max_tokens=128):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PERFORMANCE PROFILING\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    \n",
    "    monitor.enabled = True\n",
    "    monitor.timings.clear()\n",
    "    monitor.counts.clear()\n",
    "    \n",
    "    _, stats = run_enhanced_vspec(\n",
    "        prompt, max_new=max_tokens,\n",
    "        use_tree=True, use_cascade=True, verbose=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTotal time: {stats['time']:.3f}s\")\n",
    "    print(f\"Tokens generated: {max_tokens}\")\n",
    "    print(f\"Speed: {stats['tokens_per_sec']:.2f} tokens/sec\")\n",
    "    \n",
    "    print(\"\\nTime breakdown:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if stats['time_breakdown']:\n",
    "        sorted_timings = sorted(\n",
    "            stats['time_breakdown'].items(),\n",
    "            key=lambda x: x[1]['total_s'],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        total_tracked = sum(t[1]['total_s'] for t in sorted_timings)\n",
    "        \n",
    "        for name, info in sorted_timings:\n",
    "            pct = (info['total_s'] / stats['time']) * 100\n",
    "            print(f\"{name:20s}: {info['total_s']:.3f}s ({pct:5.1f}%) \"\n",
    "                  f\"[{info['count']:3d} calls, {info['mean_ms']:.2f}ms avg]\")\n",
    "        \n",
    "        untracked = stats['time'] - total_tracked\n",
    "        untracked_pct = (untracked / stats['time']) * 100\n",
    "        print(f\"{'Untracked':20s}: {untracked:.3f}s ({untracked_pct:5.1f}%)\")\n",
    "    \n",
    "    print(\"\\nKey metrics:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Target calls: {stats['target_calls']}\")\n",
    "    print(f\"Drafter calls: {stats['drafter_calls']}\")\n",
    "    print(f\"Blocks verified: {stats['blocks']}\")\n",
    "    print(f\"Mean acceptance: {stats['mean_accept']:.2f} tokens/block\")\n",
    "    print(f\"Tree explorations: {stats['tree_explores']}\")\n",
    "    if stats['cascade_stages']:\n",
    "        print(f\"Avg cascade stage: {np.mean(stats['cascade_stages']):.2f}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def compare_on_prompt_types():\n",
    "    prompt_types = {\n",
    "        'math': \"Calculate 1247 * 892 step by step, showing all work.\",\n",
    "        'code': \"Write a Python function to implement quicksort with detailed comments.\",\n",
    "        'reasoning': \"Explain the theory of relativity to a 10-year-old.\",\n",
    "        'creative': \"Write a haiku about artificial intelligence.\",\n",
    "        'factual': \"List the main causes of the French Revolution.\",\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PERFORMANCE BY PROMPT TYPE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for ptype, prompt in prompt_types.items():\n",
    "        print(f\"\\n{ptype.upper()}: {prompt[:50]}...\")\n",
    "    \n",
    "        greedy = run_greedy_cached(prompt, max_new=128)\n",
    "        \n",
    "        _, enhanced = run_enhanced_vspec(\n",
    "            prompt, max_new=128,\n",
    "            use_tree=True, use_cascade=True, verbose=False\n",
    "        )\n",
    "        \n",
    "        speedup = enhanced['tokens_per_sec'] / greedy['tokens_per_s']\n",
    "        results[ptype] = {\n",
    "            'greedy_tps': greedy['tokens_per_s'],\n",
    "            'enhanced_tps': enhanced['tokens_per_sec'],\n",
    "            'speedup': speedup,\n",
    "            'mean_accept': enhanced['mean_accept']\n",
    "        }\n",
    "        \n",
    "        print(f\"  Greedy: {greedy['tokens_per_s']:.1f} tok/s\")\n",
    "        print(f\"  Enhanced: {enhanced['tokens_per_sec']:.1f} tok/s\")\n",
    "        print(f\"  Speedup: {speedup:.2f}x\")\n",
    "        print(f\"  Acceptance: {enhanced['mean_accept']:.1f} tokens/block\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY BY TYPE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    df_types = pd.DataFrame(results).T\n",
    "    df_types = df_types.sort_values('speedup', ascending=False)\n",
    "    print(df_types.to_string())\n",
    "    \n",
    "    return results\n",
    "\n",
    "def test_adaptive_behavior(prompt=\"Explain machine learning.\", iterations=5):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ADAPTIVE BEHAVIOR TEST\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Running same prompt {iterations} times to see adaptation...\")\n",
    "    \n",
    "    results = []\n",
    "    for i in range(iterations):\n",
    "        print(f\"\\nIteration {i+1}/{iterations}\")\n",
    "        _, stats = run_enhanced_vspec(\n",
    "            prompt, max_new=100,\n",
    "            use_tree=True, use_cascade=True, verbose=False\n",
    "        )\n",
    "        results.append({\n",
    "            'iteration': i+1,\n",
    "            'tps': stats['tokens_per_sec'],\n",
    "            'mean_accept': stats['mean_accept'],\n",
    "            'target_calls': stats['target_calls']\n",
    "        })\n",
    "        print(f\"  Speed: {stats['tokens_per_sec']:.1f} tok/s\")\n",
    "        print(f\"  Acceptance: {stats['mean_accept']:.1f}\")\n",
    "    tps_values = [r['tps'] for r in results]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"STATISTICS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Mean speed: {np.mean(tps_values):.1f} ± {np.std(tps_values):.1f} tok/s\")\n",
    "    print(f\"Min speed: {np.min(tps_values):.1f} tok/s\")\n",
    "    print(f\"Max speed: {np.max(tps_values):.1f} tok/s\")\n",
    "    print(f\"Coefficient of variation: {np.std(tps_values)/np.mean(tps_values):.2%}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"INTERACTIVE DEMO FUNCTIONS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. quick_test(prompt, max_tokens)\")\n",
    "print(\"   - Compare all methods on a single prompt\")\n",
    "print(\"   - Example: quick_test('Explain quantum computing', 256)\")\n",
    "print(\"\\n2. profile_performance(prompt, max_tokens)\")\n",
    "print(\"   - Detailed performance profiling\")\n",
    "print(\"   - Shows where time is spent\")\n",
    "print(\"\\n3. compare_on_prompt_types()\")\n",
    "print(\"   - Test on different prompt categories\")\n",
    "print(\"   - Math, code, reasoning, creative, factual\")\n",
    "print(\"\\n4. test_adaptive_behavior(prompt, iterations)\")\n",
    "print(\"   - Test consistency across multiple runs\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "print(\"\\nRunning quick demo...\")\n",
    "demo_results = quick_test(\"What are the benefits of renewable energy?\", max_tokens=128)\n",
    "\n",
    "_ = quick_test(\"What is transfer learning?\", max_tokens=128)\n",
    "_ = profile_performance(\"Implement a binary search in Python.\", max_tokens=128)\n",
    "by_type = compare_on_prompt_types()\n",
    "adapt   = test_adaptive_behavior(\"How does a transformer model work?\", iterations=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b360e0-a0c7-48ab-9db1-df06990b285b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
